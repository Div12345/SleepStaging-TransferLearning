{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RP SSL Model - Sleep TL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k7DQCk6Pj6m2",
        "xGXrVF9HW_4_",
        "36TDjBbbTrib",
        "_DOn7lfOsZaN",
        "S6jOpA6U40KV"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMp+7Lzexjt1O+Sahm5aQs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c38469a2d1f74d3387f402a361903523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74295ebc0fcd413b9a75914fbc0d1752",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c38ab60816ad474689b20ce12f8df3e3",
              "IPY_MODEL_dda9972ba5a94292a5cc08ca99b85bb9"
            ]
          }
        },
        "74295ebc0fcd413b9a75914fbc0d1752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c38ab60816ad474689b20ce12f8df3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_eebede281c424c5da51b65709f652d68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.23MB of 1.23MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9731bb1d6ef24e7c8508636313972df9"
          }
        },
        "dda9972ba5a94292a5cc08ca99b85bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8bd49ea4c16246f6bbfc0f9e2253126b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_888c08f31b4147e7951105d297fe6315"
          }
        },
        "eebede281c424c5da51b65709f652d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9731bb1d6ef24e7c8508636313972df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bd49ea4c16246f6bbfc0f9e2253126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "888c08f31b4147e7951105d297fe6315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e872f1bd30e4e8bb82402e00cab4563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb30808baa4a406da9265ddbda1889f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c867d8d9450c4a5fb0ff2b93a87b4994",
              "IPY_MODEL_8bc1ce3c46dd4b0db7ef8134b1ec24e1"
            ]
          }
        },
        "bb30808baa4a406da9265ddbda1889f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c867d8d9450c4a5fb0ff2b93a87b4994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_93c22be09feb4057bf2c2b134bfc8072",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3f100c06ad04078873a0327d1f1001b"
          }
        },
        "8bc1ce3c46dd4b0db7ef8134b1ec24e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e8b52b61eab4b3b9faf77b33602cf55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dc8b4ce1f584fa9b9f0fda2253530e8"
          }
        },
        "93c22be09feb4057bf2c2b134bfc8072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3f100c06ad04078873a0327d1f1001b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e8b52b61eab4b3b9faf77b33602cf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dc8b4ce1f584fa9b9f0fda2253530e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91aac24d57c44263a762c551b1412e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58706cd4cc0b4b6595238461f145194f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_896abb471fa0480f8967f8aa8f585050",
              "IPY_MODEL_afcf3abe5bbc44ba9ac2ccf0c6afc9f1"
            ]
          }
        },
        "58706cd4cc0b4b6595238461f145194f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "896abb471fa0480f8967f8aa8f585050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_4aecf725a07b4ec7b5bc36fdbda2ffbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7818a58c63274658bf29b8561634100a"
          }
        },
        "afcf3abe5bbc44ba9ac2ccf0c6afc9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a309cd9858d34ba390ca61e5f13a7c01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8498c6cb5a934ee2b74c7cc854e94822"
          }
        },
        "4aecf725a07b4ec7b5bc36fdbda2ffbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7818a58c63274658bf29b8561634100a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a309cd9858d34ba390ca61e5f13a7c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8498c6cb5a934ee2b74c7cc854e94822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Div12345/SleepStaging-TransferLearning/blob/main/RP_SSL_Model_Sleep_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N9BXW0Weea5"
      },
      "source": [
        "# Self-Supervised Learning on EEG with Relative Positioning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_iw4rwA0ReF"
      },
      "source": [
        "Uncovering the structure of clinical EEG signals with self-supervised learning - \n",
        "[Paper](https://arxiv.org/pdf/2007.16104.pdf)\n",
        "\n",
        "Options for SSL - \n",
        "1. Autoencoder\n",
        "2. Relative Positioning\n",
        "3. Temporal Shuffling\n",
        "4. Contrastive Predictive Coding\n",
        "\n",
        "From everything, the paper shows better performance with Relative Positioning I think"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKREcnlidFSe",
        "cellView": "form"
      },
      "source": [
        "#@title Dependencies Install\n",
        "!pip install wandb\n",
        "!pip install git+https://github.com/sylvchev/beetl-competition\n",
        "!pip install moabb\n",
        "!pip install braindecode\n",
        "!pip install git+https://github.com/pyRiemann/pyRiemann\n",
        "!pip install matplotlib\n",
        "!pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgpOWEyAdgBr",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "from mne import get_config, set_config\n",
        "import os.path as osp\n",
        "import os\n",
        "from beetl.task_datasets import BeetlSleepLeaderboard, BeetlSleepSource\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "import logging\n",
        "\n",
        "import braindecode\n",
        "from braindecode import EEGClassifier\n",
        "from braindecode.util import np_to_var, set_random_seeds\n",
        "from braindecode.models import SleepStagerChambon2018\n",
        "from braindecode.datautil.preprocess import preprocess, Preprocessor, zscore\n",
        "from braindecode.samplers.ssl import RelativePositioningSampler\n",
        "#from braindecode.datautil import create_from_X_y\n",
        "from braindecode.datasets import BaseDataset\n",
        "\n",
        "from braindecode.datasets import BaseDataset, BaseConcatDataset\n",
        "from braindecode.datautil import create_fixed_length_windows\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, cohen_kappa_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "import skorch\n",
        "import skorch.dataset\n",
        "from skorch.callbacks import EarlyStopping, Checkpoint, EpochScoring, WandbLogger, TrainEndCheckpoint\n",
        "from skorch.dataset import Dataset\n",
        "from skorch.helper import predefined_split\n",
        "\n",
        "import time\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchsampler import ImbalancedDatasetSampler as IDS\n",
        "\n",
        "import wandb\n",
        "\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy-fjyikdmIx",
        "outputId": "82971541-cb2f-4537-88fb-d78b1d809b6e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKNGbIduxb2z"
      },
      "source": [
        "Wandb setup\n",
        "\n",
        "Documentation for Skorch Adaption - [Link](https://gitbook-docs.wandb.ai/guides/integrations/other/skorch), [Simple Colab](https://colab.research.google.com/drive/1Bo8SqN1wNPMKv5Bn9NjwGecBxzFlaNZn?usp=sharing#scrollTo=9AoMDvXXpaUT), [Step by Step Tut](https://wandb.ai/cayush/uncategorized/reports/Automate-Kaggle-model-training-with-Skorch-and-W-B--Vmlldzo4NTQ1NQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0mj1Fdvx9KI",
        "outputId": "30dd0f69-7801-4980-d7b3-10701c15ed87"
      },
      "source": [
        "!wandb login\n",
        "# Specific to user - Put it here for convinience\n",
        "# 7018335e3eae8802cd03eeeb536cd1bc36ccbc7b # should remove it later when publishing ig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqH7RRnadrW-",
        "outputId": "9d25e8cc-5b49-495b-bf2a-6ab5567cb97f"
      },
      "source": [
        "mne.set_log_level(False) # Equivalent to WARNING\n",
        "path = \"/content/drive/MyDrive/mne_data\"\n",
        "set_config(\"MNE_DATA\", path)\n",
        "set_config(\"MNE_DATASETS_BEETLSLEEPLEADERBOARD_PATH\",path)\n",
        "set_config(\"MNE_DATASETS_BEETLSLEEPSOURCE_PATH\",path)\n",
        "get_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-d9ce88047e42>:4: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BEETLSLEEPLEADERBOARD_PATH\"\n",
            "  set_config(\"MNE_DATASETS_BEETLSLEEPLEADERBOARD_PATH\",path)\n",
            "<ipython-input-12-d9ce88047e42>:5: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BEETLSLEEPSOURCE_PATH\"\n",
            "  set_config(\"MNE_DATASETS_BEETLSLEEPSOURCE_PATH\",path)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MNE_DATA': '/content/drive/MyDrive/mne_data',\n",
              " 'MNE_DATASETS_BEETLSLEEPLEADERBOARD_PATH': '/content/drive/MyDrive/mne_data',\n",
              " 'MNE_DATASETS_BEETLSLEEPSOURCE_PATH': '/content/drive/MyDrive/mne_data'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ags-d-OWkiGp",
        "outputId": "c190b045-b412-471c-e6de-dc96c3b8ddd7"
      },
      "source": [
        "cuda = torch.cuda.is_available()  # check if GPU is available\n",
        "device = 'cuda' if cuda else 'cpu'\n",
        "print(device)\n",
        "if cuda:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "# Set random seed to be able to reproduce results\n",
        "set_random_seeds(seed=87, cuda=cuda)\n",
        "random_state = 87\n",
        "# print num_workers available\n",
        "# \n",
        "!nvidia-smi -L\n",
        "# !nvidia-smi -q\n",
        "\n",
        "# gpu = cuda.get_current_device()\n",
        "# print(\"maxThreadsPerBlock = %s\" % str(gpu.MAX_THREADS_PER_BLOCK))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-e69cecc5-d4a3-e7f5-0384-2ff76d35e84a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XafeqFx8d2pu",
        "cellView": "form"
      },
      "source": [
        "#@title Helper Functions\n",
        "\n",
        "def label_count(y_train):\n",
        "  labels= np.unique(y_train)\n",
        "  labelsize=labels.shape[0]\n",
        "  #print('labelsize:',labelsize)\n",
        "  label_count = np.zeros(labelsize).astype(int)\n",
        "  for i in range(labelsize):\n",
        "      # tempy = ys1[ys1==labels[i]]\n",
        "      label_count[i]=y_train[y_train==labels[i]].shape[0]\n",
        "  maxsize = label_count.max()\n",
        "  print(label_count)\n",
        "  return np_to_var(label_count)\n",
        "\n",
        "def label_viz(y):\n",
        "  # Another Nice func with viz\n",
        "  classes_mapping = {0: 'W', 1: 'S1', 2: 'S2', 3: 'S3', 4: 'S4', 5:'REM'}\n",
        "  # This might be a time consuming method though\n",
        "  y_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\n",
        "  ax = y_train.value_counts().plot(kind='barh')\n",
        "  ax.set_xlabel('Number of training examples');\n",
        "  ax.set_ylabel('Sleep stage');\n",
        "\n",
        "# For trained Skorch model\n",
        "def training_viz(clf):\n",
        "  # For Trained Skorch Classifier\n",
        "  df = pd.DataFrame(clf.history.to_list())\n",
        "  df[['train_mis_clf', 'valid_mis_clf']] = 100 - df[\n",
        "      ['train_bacc', 'valid_bacc']] * 100\n",
        "\n",
        "  # get percent of misclass for better visual comparison to loss\n",
        "  plt.style.use('seaborn-talk')\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 7))\n",
        "  df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
        "      ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False,\n",
        "      fontsize=14)\n",
        "\n",
        "  ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
        "  ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
        "\n",
        "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "  df.loc[:, ['train_mis_clf', 'valid_mis_clf']].plot(\n",
        "      ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\n",
        "  ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
        "  ax2.set_ylabel('Balanced misclassification rate [%]', color='tab:red',\n",
        "                fontsize=14)\n",
        "  ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
        "  ax1.set_xlabel('Epoch', fontsize=14)\n",
        "\n",
        "  # where some data has already been plotted to ax\n",
        "  handles = []\n",
        "  handles.append(\n",
        "      Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
        "  handles.append(\n",
        "      Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
        "  plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
        "  plt.tight_layout()\n",
        "\n",
        "# Scaling the data\n",
        "class TrainObject(object):\n",
        "    # Scaling the data\n",
        "    def __init__(self, X, y, nps= False):\n",
        "        assert len(X) == len(y)\n",
        "        # mean = np.mean(X, axis=2, keepdims=True)\n",
        "        # # Here normalise across the window, when channel size is not large enough\n",
        "        # # In motor imagery kit, we put axis = 1, across channel as an example\n",
        "        # std = np.std(X, axis=2, keepdims=True)\n",
        "        # X = (X - mean) / std\n",
        "        X = zscore(X)\n",
        "        # we scale it to 1000 as a better training scale of the shallow CNN\n",
        "        # according to the orignal work of the paper referenced above\n",
        "        if (nps == False):\n",
        "          self.X = np_to_var(X.astype(np.float32)*1e3).to(device)\n",
        "          self.y = np_to_var(y.astype(np.int8)).to(device)\n",
        "        else:\n",
        "          self.X = X.astype(np.float32)*1e3\n",
        "          self.y = y.astype(np.int8)\n",
        "          # Keeping y in float here will be better for the direct skorch case\n",
        "\n",
        "# To update for the cases data is already available\n",
        "def predict_leaderboard_unlabelled(clf,save_fname,x_test_data = None,emb = False,nps=False):\n",
        "  # Test Data - 6 to 17 - 12 subjects \n",
        "  if x_test_data is None:\n",
        "    _, _, X_test, _ = dsl.get_data(subjects=range(6, 18)) \n",
        "    print(\"Sleep leaderboard - Test Data : There are {} trials with {} electrodes and {} time samples\".format(*X_test.shape))\n",
        "\n",
        "    # print(X_test.shape[0])\n",
        "\n",
        "    x_test_mean = TrainObject(X_test, y = np.zeros(X_test.shape[0]),nps=nps)\n",
        "    if (nps==False):\n",
        "      # means torch must've been the input to the classifier\n",
        "      x_test_data = Dataset(x_test_mean.X,x_test_mean.y)\n",
        "      # Maybe put a tqdm bar?\n",
        "      y_pred = clf.predict(x_test_data)\n",
        "    else:\n",
        "      x_test_data = x_test_mean \n",
        "      y_pred = clf.predict(x_test_data.X)\n",
        "  else:\n",
        "    y_pred = clf.predict(x_test_data)\n",
        "  print(X_test.shape)\n",
        "\n",
        "  print(\"Checking if all classes have been predicted\")\n",
        "  print(np.unique(y_pred))\n",
        "\n",
        "  np.savetxt(\"/content/drive/MyDrive/mne_data/predict/\"+save_fname+\".txt\",y_pred,delimiter=',',fmt=\"%d\")\n",
        "\n",
        "def custom_create_from_X_y(\n",
        "  \n",
        "        X, y, sfreq , drop_last_window=False, ch_names=None, window_size_samples=None,\n",
        "        window_stride_samples=None,preload=False,n_jobs=1):\n",
        "    \"\"\"Create a BaseConcatDataset of WindowsDatasets from X and y to be used for\n",
        "    decoding with skorch and braindecode, where X is a list of pre-cut trials\n",
        "    and y are corresponding targets.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: array-like\n",
        "        list of pre-cut trials as n_trials x n_channels x n_times\n",
        "    y: array-like\n",
        "        targets corresponding to the trials\n",
        "    drop_last_window: bool\n",
        "        whether or not have a last overlapping window, when\n",
        "        windows/windows do not equally divide the continuous signal\n",
        "    sfreq: float\n",
        "        Sampling frequency of signals.\n",
        "    ch_names: array-like\n",
        "        Names of the channels.\n",
        "    window_size_samples: int\n",
        "        window size\n",
        "    window_stride_samples: int\n",
        "        stride between windows\n",
        "    Returns\n",
        "    -------\n",
        "    windows_datasets: BaseConcatDataset\n",
        "        X and y transformed to a dataset format that is compatible with skorch\n",
        "        and braindecode\n",
        "    \"\"\"\n",
        "    # Prevent circular import\n",
        "    # from braindecode.preprocessing.windowers import (\n",
        "    #     create_fixed_length_windows, )\n",
        "    n_samples_per_x = []\n",
        "    base_datasets = []\n",
        "    if ch_names is None:\n",
        "        ch_names = [str(i) for i in range(X.shape[1])]\n",
        "        log.info(f\"No channel names given, set to 0-{X.shape[1]}).\")\n",
        "\n",
        "    for x, target in zip(X, y):\n",
        "        n_samples_per_x.append(x.shape[1])\n",
        "        info = mne.create_info(ch_names=ch_names, sfreq=sfreq)\n",
        "        raw = mne.io.RawArray(x, info)\n",
        "        base_dataset = BaseDataset(raw, pd.Series({\"target\": target}),\n",
        "                                   target_name=\"target\")\n",
        "        # Also add option to give further description in line above for subject,run,session\n",
        "        base_datasets.append(base_dataset)\n",
        "    base_datasets = BaseConcatDataset(base_datasets)\n",
        "\n",
        "    if window_size_samples is None and window_stride_samples is None:\n",
        "        if not len(np.unique(n_samples_per_x)) == 1:\n",
        "            raise ValueError(\"if 'window_size_samples' and \"\n",
        "                             \"'window_stride_samples' are None, \"\n",
        "                             \"all trials have to have the same length\")\n",
        "        window_size_samples = n_samples_per_x[0]\n",
        "        window_stride_samples = n_samples_per_x[0]\n",
        "    windows_datasets = create_fixed_length_windows(\n",
        "        base_datasets,\n",
        "        start_offset_samples=0,\n",
        "        stop_offset_samples=None, # this makes it consider it the end of the recording\n",
        "        window_size_samples=window_size_samples,\n",
        "        window_stride_samples=window_stride_samples,\n",
        "        drop_last_window=drop_last_window,\n",
        "        preload = preload,\n",
        "        n_jobs = n_jobs\n",
        "    )\n",
        "    return windows_datasets\n",
        "\n",
        "def data_save(BrainDecode_data,fname):\n",
        "  # convert all trainB,valB,testB into dict and save\n",
        "  # BrainDecode_data = dict()\n",
        "  # BrainDecode_data[\"train\"] = trainB\n",
        "  # BrainDecode_data[\"valid\"] = valB\n",
        "  # BrainDecode_data[\"test\"] = testB\n",
        "\n",
        "  save_path = \"/content/drive/MyDrive/mne_data/\" \n",
        "  with open(save_path+fname+'.pkl', 'wb') as f:\n",
        "    pickle.dump(BrainDecode_data, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from time import time as t\n",
        "def load_obj(path,name):\n",
        "  target = path + name + '.pkl'\n",
        "  with open(target, 'rb') as f:\n",
        "    unpickler = pickle.Unpickler(f)\n",
        "    a = unpickler.load()\n",
        "    return a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoaRNrI_mOd"
      },
      "source": [
        "#@title Helper functions for loading data\n",
        "# B - phase 1, C - phase 2\n",
        "# get_testC will be same simple similar to testB\n",
        "# But get_valC has to be the similar long-winded route like trainB, valB\n",
        "\n",
        "\n",
        "def get_trainB():\n",
        "  start = time.time()\n",
        "  dss = BeetlSleepSource()\n",
        "  X_train_list, y_train_list, trsubj = [], [], []\n",
        "  for i in range(39):\n",
        "    a, b, _ = dss.get_data(subjects = [i])\n",
        "    X_train_list.append(a)\n",
        "    y_train_list.append(b)\n",
        "    trsubj.append([i]*y_train_list[i].shape[0])\n",
        "    # print(i)\n",
        "    # print(y_train_list[i].shape[0])\n",
        "  end = time.time()\n",
        "  print(f\"training data load time = {(end-start)/60} min\")\n",
        "\n",
        "  print(len(trsubj))\n",
        "  print(len(X_train_list))\n",
        "  print(y_train_list)\n",
        "  print(X_train_list[0].shape)\n",
        "  print(X_train_list[1].shape)\n",
        "  X_train = np.concatenate(X_train_list,0)\n",
        "  y_train = np.concatenate(y_train_list,0)\n",
        "\n",
        "  print(X_train.shape,y_train.shape)\n",
        "  del X_train_list,y_train_list\n",
        "  # For the Sleep Physionet in Braindecode, this is the desc used\n",
        "  # desc = pd.Series({'subject': subj_nb, 'recording': sess_nb}, name='')\n",
        "\n",
        "  sfreq = 100\n",
        "  # z-scoring or normalizing\n",
        "\n",
        "  # start = time.time()\n",
        "  trainX = TrainObject(X_train, y = y_train, nps = True)\n",
        "  end = time.time()\n",
        "  print(f\"Z-scoring time {end-start}\")\n",
        "\n",
        "  # train = Dataset(trainX.X,trainX.y)\n",
        "  # For braindecode - returns BaseConcatDatset \n",
        "  # - Seems this is also compatible with skorch\n",
        "\n",
        "  start = time.time()\n",
        "  trainB = custom_create_from_X_y(trainX.X,trainX.y, sfreq = 100, preload = True, n_jobs = -1)\n",
        "  # Nah this mne type structure seems way to wasteful.. Can rather just write own implementation of the sampler from pytorch Dataset I think\n",
        "  # It took a long time, but RAM sort of cleared out after running, not bad\n",
        "  end = time.time()\n",
        "  print(f\"Braindecode dataset time {end-start} sec = {(end-start)/60} min\")\n",
        "  # 10 sec + 7 min\n",
        "  len(trainB.datasets)\n",
        "  # trainB.datasets\n",
        "  print(dir(trainB))\n",
        "  print(type(trainB.description)) # pd.Series\n",
        "  train_subj = np.concatenate(trsubj)\n",
        "  print(train_subj.shape)\n",
        "\n",
        "  y = 0\n",
        "  for i,ds in enumerate(trainB.datasets):\n",
        "    ds.description[\"subject\"] = train_subj[i]\n",
        "    if (i==0):\n",
        "      y = 0\n",
        "    elif (train_subj[i]!=train_subj[i-1]):\n",
        "      y = 0\n",
        "    ds.windows.metadata['i_window_in_trial'] = y\n",
        "    ds.windows.metadata['i_start_in_trial'] = y*3000\n",
        "    ds.windows.metadata['i_stop_in_trial'] = (y+1)*3000\n",
        "    y+=1\n",
        "  # _compute_window_inds from braindecode.preprocessing.windowers\n",
        "  # Raise issue to include this in create_from_X_y if the param set that subject data is cont?\n",
        "  # trainB.description[\"subject\"] = train_subj\n",
        "  print(trainB.description)\n",
        "\n",
        "  # 3 sec + 1.5 min\n",
        "  return trainB\n",
        "\n",
        "def get_valB():\n",
        "  # valB\n",
        "  # Labelled Leaderboard Data\n",
        "  start = time.time()\n",
        "  dsl = BeetlSleepLeaderboard()\n",
        "  # dsl.get_data()\n",
        "\n",
        "  # Validation Data - 5? 6? subjects from the test group - Competition says 5, looks like 6\n",
        "\n",
        "  X_target_list, y_target_list, tssubj = [], [], []\n",
        "  for i in range(6):\n",
        "    a, b, _,_ = dsl.get_data(subjects = [i])\n",
        "    X_target_list.append(a)\n",
        "    y_target_list.append(b)\n",
        "    tssubj.append([i]*y_target_list[i].shape[0])\n",
        "    # print(y_target_list[i].shape[0])\n",
        "  end = time.time()\n",
        "  print(f\"leaderboard labelled load time = {(end-start)/60} min\")\n",
        "\n",
        "  print(len(tssubj))\n",
        "  print(len(X_target_list))\n",
        "  print(y_target_list)\n",
        "\n",
        "  # X_target, y_target, _, _ = dsl.get_data(subjects=range(0,6))\n",
        "  # label_count(y_target_list[5]) # Seems like there are 6 valid subjects in the labelled leaderboard\n",
        "  # print(X_target_list[0].shape)\n",
        "  # print(X_target_list[1].shape)\n",
        "\n",
        "  X_target = np.concatenate(X_target_list,0)\n",
        "  y_target = np.concatenate(y_target_list,0)\n",
        "  sfreq = 100\n",
        "  print(X_target.shape,y_target.shape)\n",
        "  del X_target_list,y_target_list\n",
        "  label_count(y_target)\n",
        "  # z-scoring or normalizing\n",
        "  start = time.time()\n",
        "  valX = TrainObject(X_target, y = y_target, nps = True)\n",
        "  end = time.time()\n",
        "  print(f\"Z-scoring time {end-start} sec\")\n",
        "  # val = Dataset(valX.X,valX.y)\n",
        "  # for braindecode\n",
        "  start = time.time()\n",
        "  valB = custom_create_from_X_y(valX.X,valX.y, sfreq = 100, preload = True, n_jobs = -1)\n",
        "  end = time.time()\n",
        "  print(f\"Braindecode dataset time {end-start} sec = {(end-start)/60} min\")\n",
        "\n",
        "  # Since I need to use this for RP task training purposes too, \n",
        "  # Need to add the time modification stuff here too\n",
        "  # 10 sec + 7 min\n",
        "  len(valB.datasets)\n",
        "  # trainB.datasets\n",
        "  print(dir(valB))\n",
        "  print(type(valB.description)) # pd.Series\n",
        "  ts_subj = np.concatenate(tssubj)\n",
        "  print(ts_subj.shape)\n",
        "\n",
        "  y = 0\n",
        "  for i,ds in enumerate(valB.datasets):\n",
        "    ds.description[\"subject\"] = ts_subj[i]\n",
        "    if (i==0):\n",
        "      y = 0\n",
        "    elif (ts_subj[i]!=ts_subj[i-1]):\n",
        "      y = 0\n",
        "    ds.windows.metadata['i_window_in_trial'] = y\n",
        "    ds.windows.metadata['i_start_in_trial'] = y*3000\n",
        "    ds.windows.metadata['i_stop_in_trial'] = (y+1)*3000\n",
        "    y+=1\n",
        "  # _compute_window_inds from braindecode.preprocessing.windowers\n",
        "  # Raise issue to include this in create_from_X_y if the param set that subject data is cont?\n",
        "  # valB.description[\"subject\"] = ts_subj\n",
        "  print(valB.description)\n",
        "\n",
        "  return valB\n",
        "\n",
        "def get_testB():\n",
        "  dsl = BeetlSleepLeaderboard()\n",
        "  _, _, X_test, _ = dsl.get_data(subjects=range(6, 18)) \n",
        "  print(\"Sleep leaderboard - Test Data : There are {} trials with {} electrodes and {} time samples\".format(*X_test.shape))\n",
        "  # print(X_test.shape[0])\n",
        "  # x_test_mean = TrainObject(X_test, y = np.zeros(X_test.shape[0]),nps=nps)\n",
        "\n",
        "  # z-scoring or normalizing\n",
        "  start = time.time()\n",
        "  testX = TrainObject(X_test, y = np.zeros(X_test.shape[0]), nps = True)\n",
        "  end = time.time()\n",
        "  print(f\"Z-scoring time {end-start} sec\")\n",
        "  # val = Dataset(valX.X,valX.y)\n",
        "  # for braindecode\n",
        "  start = time.time()\n",
        "  testB = custom_create_from_X_y(testX.X,testX.y, sfreq = 100, preload = True, n_jobs = -1)\n",
        "  end = time.time()\n",
        "  print(f\"Braindecode dataset time {end-start} sec = {(end-start)/60} min\")\n",
        "  return testB\n",
        "\n",
        "\n",
        "def get_valC():\n",
        "  # Phase 2 Target Data\n",
        "  # Need to download by myself first\n",
        "  target_savebase = '/content/drive/MyDrive/mne_data/MNE-beetlsleeptest-data/sleep_target/'\n",
        "  X_sleep_target = []\n",
        "  y_sleep_target = []\n",
        "  tssubj = []\n",
        "  #from s0-s4 in final set\n",
        "  start = time.time()\n",
        "  for subj in range(0, 5):\n",
        "    for session in range(1, 3):\n",
        "      # \"testing_s{}r{}X.npy\", replacing \"leaderboard_s{}r{}X.npy\" before\n",
        "      with open(target_savebase + \"testing_s{}r{}X.npy\".format(subj, session), 'rb') as f:\n",
        "        X_sleep_target.append(pickle.load(f))\n",
        "      with open(target_savebase + \"testing_s{}r{}y.npy\".format(subj, session), 'rb') as g:\n",
        "        y_sleep_target.append(pickle.load(g))\n",
        "      \n",
        "      tssubj.append([subj]*y_sleep_target[2*subj+session-1].shape[0])\n",
        "  \n",
        "  end = time.time()\n",
        "  print(f\"phase 2 labelled load time = {(end-start)/60} min\")\n",
        "\n",
        "  print(len(tssubj))\n",
        "  print(len(X_sleep_target))\n",
        "  print(y_sleep_target)\n",
        "  # print(X_sleep_target[0].shape)\n",
        "  # print(X_sleep_target[1].shape)\n",
        "\n",
        "  X_sleep_target = np.concatenate(X_sleep_target)\n",
        "  y_sleep_target = np.concatenate(y_sleep_target)\n",
        "  sfreq = 100\n",
        "\n",
        "  print(\"There are {} trials with {} electrodes and {} time samples\".format(*X_sleep_target.shape))\n",
        "  print(X_sleep_target.shape, y_sleep_target.shape)\n",
        "  label_count(y_sleep_target)\n",
        "\n",
        "  # package in torch dataset with mean normalizing\n",
        "  # z-scoring or normalizing\n",
        "  start = time.time()\n",
        "  valX = TrainObject(X_sleep_target, y = y_sleep_target, nps = True)\n",
        "  end = time.time()\n",
        "  print(f\"Z-scoring time {end-start} sec\")\n",
        "\n",
        "  \n",
        "  # for braindecode\n",
        "  start = time.time()\n",
        "  # valC = Dataset(valX.X,valX.y)\n",
        "  valC = custom_create_from_X_y(valX.X,valX.y, sfreq = 100, preload = True, n_jobs = -1)\n",
        "  end = time.time()\n",
        "  print(f\"Braindecode dataset time {end-start} sec = {(end-start)/60} min\")\n",
        "  # \n",
        "\n",
        "  # Since I need to use this for RP task training purposes too, \n",
        "  # Need to add the time modification stuff here too\n",
        "  # 10 sec + 7 min\n",
        "  len(valC.datasets)\n",
        "  # trainB.datasets\n",
        "  print(dir(valC))\n",
        "  print(type(valC.description)) # pd.Series\n",
        "  ts_subj = np.concatenate(tssubj)\n",
        "  print(ts_subj.shape)\n",
        "\n",
        "  y = 0\n",
        "  for i,ds in enumerate(valC.datasets):\n",
        "    ds.description[\"subject\"] = ts_subj[i]\n",
        "    if (i==0):\n",
        "      y = 0\n",
        "    elif (ts_subj[i]!=ts_subj[i-1]):\n",
        "      y = 0\n",
        "    ds.windows.metadata['i_window_in_trial'] = y\n",
        "    ds.windows.metadata['i_start_in_trial'] = y*3000\n",
        "    ds.windows.metadata['i_stop_in_trial'] = (y+1)*3000\n",
        "    y+=1\n",
        "  # _compute_window_inds from braindecode.preprocessing.windowers\n",
        "  # Raise issue to include this in create_from_X_y if the param set that subject data is cont?\n",
        "  # valC.description[\"subject\"] = ts_subj\n",
        "  print(valC.description)\n",
        "\n",
        "  return valC\n",
        "\n",
        "def get_testC():\n",
        "  # Phase 2 Test Data - Need to download by myself first\n",
        "  test_savebase = '/content/drive/MyDrive/mne_data/MNE-beetlsleeptest-data/testing/'\n",
        "  X_sleep_test = []\n",
        "  start = time.time()\n",
        "\n",
        "  #starts from s5 in final set\n",
        "  for subj in range(5, 14):\n",
        "      for session in range(1, 3):\n",
        "          # \"testing_s{}r{}X.npy\", replacing \"leaderboard_s{}r{}X.npy\" before\n",
        "          with open(test_savebase + \"testing_s{}r{}X.npy\".format(subj, session), 'rb') as f:\n",
        "              X_sleep_test.append(pickle.load(f))\n",
        "  X_sleep_test = np.concatenate(X_sleep_test)\n",
        "  end = time.time()\n",
        "  print(f\"phase 2 final test set load time = {(end-start)/60} min\")\n",
        "  print (\"There are {} trials with {} electrodes and {} time samples\".format(*X_sleep_test.shape))\n",
        "\n",
        "  # package in torch dataset with mean normalizing\n",
        "  # z-scoring or normalizing\n",
        "  start = time.time()\n",
        "  testX = TrainObject(X_sleep_test, y = np.zeros(X_sleep_test.shape[0]), nps = True)\n",
        "  end = time.time()\n",
        "  print(f\"Z-scoring time {end-start} sec\")\n",
        "  sfreq = 100\n",
        "  # for braindecode\n",
        "  start = time.time()\n",
        "  # testC = Dataset(testX.X,testX.y) # Torch\n",
        "  testC = custom_create_from_X_y(testX.X,testX.y, sfreq = 100, preload = True, n_jobs = -1)\n",
        "  end = time.time()\n",
        "  print(f\"Torch dataset time {end-start} sec = {(end-start)/60} min\")\n",
        "\n",
        "  return testC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSvtzwg-v4Bi"
      },
      "source": [
        "log = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aQh982bXy9cO"
      },
      "source": [
        "#@title RPD\n",
        "\n",
        "# Train-Test Split - Not necessary here - We have our train and validation\n",
        "# train and val - skorch dataset class\n",
        "\n",
        "# TODO - Mods required - I think done\n",
        "# New Dataset class which can receive a pair of indices and return the corresponding epochs\n",
        "# RPD - RelativePositioningDataset\n",
        "from braindecode.datasets import BaseConcatDataset\n",
        "class RPD(BaseConcatDataset):\n",
        "    \"\"\"BaseConcatDataset with __getitem__ that expects 2 indices and a target.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_of_ds):\n",
        "        super().__init__(list_of_ds)\n",
        "        self.return_pair = True\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.return_pair:\n",
        "            ind1, ind2, y = index\n",
        "            # TODO - Check if the 0 indexing is required\n",
        "            return (super().__getitem__(ind1)[0],\n",
        "                    super().__getitem__(ind2)[0]), y\n",
        "            # return(super())\n",
        "        else:\n",
        "            return super().__getitem__(index)\n",
        "\n",
        "    @property\n",
        "    def return_pair(self):\n",
        "        return self._return_pair\n",
        "\n",
        "    @return_pair.setter\n",
        "    def return_pair(self, value):\n",
        "        self._return_pair = value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4GYryHvj2hP",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f18326-3a05-451a-9d7d-83a83a95cd6d"
      },
      "source": [
        "#@title SleepStagerChambon2018 model and Contrastive Net\n",
        "# Extract number of channels and time steps from dataset\n",
        "# n_channels = X_train[0].shape[0] #2\n",
        "n_channels = 2 #@param\n",
        "#print(n_channels)\n",
        "# input_size_samples = X_train[0].shape[1]\n",
        "input_size_samples = 3000 #@param\n",
        "#print(input_size_samples)\n",
        "emb_size = 100 #@param\n",
        "n_conv_chs = 16 #@param\n",
        "# dropout = 0.5\n",
        "sfreq = 100 #@param\n",
        "\n",
        "emb = SleepStagerChambon2018(\n",
        "    n_channels,\n",
        "    sfreq,\n",
        "    n_classes=emb_size,\n",
        "    n_conv_chs=n_conv_chs,\n",
        "    input_size_s=input_size_samples / sfreq,\n",
        "    dropout=0,\n",
        "    apply_batch_norm=True\n",
        ")\n",
        "\n",
        "\n",
        "class ContrastiveNet(nn.Module):\n",
        "    \"\"\"Contrastive module with linear layer on top of siamese embedder.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    emb : nn.Module\n",
        "        Embedder architecture.\n",
        "    emb_size : int\n",
        "        Output size of the embedder.\n",
        "    dropout : float\n",
        "        Dropout rate applied to the linear layer of the contrastive module.\n",
        "    \"\"\"\n",
        "    def __init__(self, emb, emb_size, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.emb = emb\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(emb_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2 = x\n",
        "        z1, z2 = self.emb(x1), self.emb(x2)\n",
        "        return self.clf(torch.abs(z1 - z2)).flatten()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDn0b8vtd3K"
      },
      "source": [
        "I don't think it's right to train the SSL on the data from the test, considering that the pre-text task is temporal.. Even though it is given as subjects in the data, I'm not sure I can be sure that it is temporally un-shuffled data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUa6cM4NHjJE"
      },
      "source": [
        "# Function based generation of trainB, valB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QutKALDgHfV0"
      },
      "source": [
        "trainB = get_trainB()\n",
        "valB = get_valB()\n",
        "# 19min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp0W_bXEIHgK"
      },
      "source": [
        "Repeat for Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi9sLyuRK1TL"
      },
      "source": [
        "# convert all trainB,valB,testB into dict and save\n",
        "BrainDecode_data = dict()\n",
        "BrainDecode_data[\"train\"] = trainB\n",
        "BrainDecode_data[\"valid\"] = valB\n",
        "# BrainDecode_data[\"test\"] = testB\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/mne_data/\" \n",
        "with open(save_path+'BraindecodeData_Dict2.pkl', 'wb') as f:\n",
        "    pickle.dump(BrainDecode_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ4vldR5LMal"
      },
      "source": [
        "# BrainDecode_data.to_pickle(save_path+'BraindecodeData_Dict3.pkl')\n",
        "del BrainDecode_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVqvKv4lLDOh"
      },
      "source": [
        "# Should run this still sometime later\n",
        "# z_dat = dict()\n",
        "# z_dat[\"train\"] = trainX\n",
        "# z_dat[\"valid\"] = valX\n",
        "# z_dat[\"test\"] = testX\n",
        "\n",
        "# save_path = \"/content/drive/MyDrive/mne_data/\" \n",
        "# with open(save_path+'zScored_np_Dict.pkl', 'wb') as f:\n",
        "#     pickle.dump(z_dat, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "##\n",
        "# Just call this file and do the follow to get tensors \n",
        "# self.X = np_to_var(X.astype(np.float32)*1e3).to(device)\n",
        "# self.y = np_to_var(y.astype(np.int8)).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x033cuVHRwZT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myo6GdoevCXN"
      },
      "source": [
        "# trainB = get_trainB\n",
        "\n",
        "valB = get_valB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQM30bBDyxtE",
        "outputId": "fe3eba5f-8121-4b84-eee5-ce2e2dc180c9"
      },
      "source": [
        "valC = get_valC()\n",
        "\n",
        "testB = get_testB()\n",
        "testC = get_testC()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phase 2 labelled load time = 0.3801357587178548 min\n",
            "10\n",
            "10\n",
            "[array([2, 2, 2, ..., 0, 2, 1], dtype=int32), array([0, 2, 0, ..., 1, 1, 2], dtype=int32), array([0, 5, 0, ..., 5, 2, 5], dtype=int32), array([2, 5, 0, ..., 2, 2, 5], dtype=int32), array([0, 5, 5, ..., 0, 5, 0], dtype=int32), array([0, 0, 0, ..., 0, 3, 5], dtype=int32), array([0, 1, 2, ..., 0, 0, 0], dtype=int32), array([0, 0, 0, ..., 1, 2, 2], dtype=int32), array([0, 0, 2, ..., 3, 2, 0], dtype=int32), array([4, 0, 2, ..., 4, 1, 4], dtype=int32)]\n",
            "There are 16568 trials with 2 electrodes and 3000 time samples\n",
            "(16568, 2, 3000) (16568,)\n",
            "[7809 1639 4704  689  145 1582]\n",
            "Z-scoring time 0.9398367404937744 sec\n",
            "Braindecode dataset time 89.99127793312073 sec = 1.4998546322186788 min\n",
            "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', 'cummulative_sizes', 'cumsum', 'cumulative_sizes', 'datasets', 'description', 'get_metadata', 'save', 'split', 'transform']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(16568,)\n",
            "       target\n",
            "0           2\n",
            "1           2\n",
            "2           2\n",
            "3           5\n",
            "4           2\n",
            "...       ...\n",
            "16563       3\n",
            "16564       2\n",
            "16565       4\n",
            "16566       1\n",
            "16567       4\n",
            "\n",
            "[16568 rows x 1 columns]\n",
            "Sleep leaderboard - Test Data : There are 25748 trials with 2 electrodes and 3000 time samples\n",
            "Z-scoring time 1.6994752883911133 sec\n",
            "Braindecode dataset time 138.8378221988678 sec = 2.3139637033144633 min\n",
            "phase 2 final test set load time = 0.5112435976664226 min\n",
            "There are 25756 trials with 2 electrodes and 3000 time samples\n",
            "Z-scoring time 2.472651481628418 sec\n",
            "Torch dataset time 140.17468452453613 sec = 2.336244742075602 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZv5jNi7vm4J",
        "outputId": "2e9203d4-86ea-4af1-fb78-fafee9657bcb"
      },
      "source": [
        "print(valB)\n",
        "print(valC)\n",
        "print(testB)\n",
        "print(testC)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<braindecode.datasets.base.BaseConcatDataset object at 0x7f26459a5650>\n",
            "<braindecode.datasets.base.BaseConcatDataset object at 0x7f2649750b50>\n",
            "<braindecode.datasets.base.BaseConcatDataset object at 0x7f2628d787d0>\n",
            "<braindecode.datasets.base.BaseConcatDataset object at 0x7f264bc8e690>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7DQCk6Pj6m2"
      },
      "source": [
        "# Relative Positioning Dataset and Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwx65i5PXi8T"
      },
      "source": [
        "# a = trainB.datasets[0]\n",
        "# dir(a)\n",
        "# a.windows.metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOPqjv0dXYgH",
        "outputId": "ba521441-412b-4e7b-a031-af9b3273505a"
      },
      "source": [
        "# split_ids = {'train': subj_train, 'valid': subj_valid, 'test': subj_test}\n",
        "splitted = dict()\n",
        "# for name, values in split_ids.items():\n",
        "#     splitted[name] = RelativePositioningDataset(\n",
        "#         [ds for ds in windows_dataset.datasets\n",
        "#          if ds.description['subject'] in values])\n",
        "from time import time as t\n",
        "s = t()\n",
        "splitted['train'] = RPD([ds for ds in trainB.datasets])\n",
        "e = t()\n",
        "print(e-s)\n",
        "s = t()\n",
        "splitted['valid'] = RPD([ds for ds in valB.datasets])\n",
        "e = t()\n",
        "print(e-s)\n",
        "s = t()\n",
        "splitted['test'] = RPD([ds for ds in valC.datasets])\n",
        "e = t()\n",
        "print(e-s)\n",
        "# get data from phase 2 validation as test sampler here\n",
        "\n",
        "# should do del(all prev data related var.s)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0512423515319824\n",
            "2.1328721046447754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csneq9PoYSue",
        "outputId": "3a06d4bc-fee3-464f-e394-2ed104d73144"
      },
      "source": [
        "a = splitted['test'].get_metadata()[0:100]\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  subject\n",
            "0                   0                 0             3000       2        0\n",
            "0                   1              3000             6000       2        0\n",
            "0                   2              6000             9000       2        0\n",
            "0                   3              9000            12000       5        0\n",
            "0                   4             12000            15000       2        0\n",
            "..                ...               ...              ...     ...      ...\n",
            "0                  95            285000           288000       0        0\n",
            "0                  96            288000           291000       0        0\n",
            "0                  97            291000           294000       1        0\n",
            "0                  98            294000           297000       0        0\n",
            "0                  99            297000           300000       2        0\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCO_SYCV-Bgv"
      },
      "source": [
        "del a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSIDRzxnWQJU"
      },
      "source": [
        "# RP samplers - randomly sample pairs of examples to train and validate model with SSL\n",
        "# 2 main hyperparams - \n",
        "# Pairs of windows that are separated by less than tau_pos samples will be given a label of 1, \n",
        "# while pairs of windows that are separated by more than tau_neg samples will be given a label of 0. \n",
        "# another param - n_examples - # pairs to sample\n",
        "# Higher number - better regularization 2000 pairs per rec in paper\n",
        "\n",
        "# Log these params in wandb\n",
        "n_examples = 2000 #250\n",
        "sfreq = 100\n",
        "tau_pos, tau_neg = int(sfreq * 60), int(sfreq * 15 * 60)\n",
        "# Should be n_examples per recording\n",
        "# print(len(splitted['train'].datasets))\n",
        "\n",
        "# n_examples_train = n_examples * len(splitted['train'].datasets)\n",
        "# n_examples_valid = n_examples * len(splitted['valid'].datasets)\n",
        "\n",
        "# n_examples_train = n_examples * 39\n",
        "n_examples_valid = n_examples * 6\n",
        "n_examples_test = n_examples * 5\n",
        "\n",
        "# print(n_examples_train,n_examples_valid)\n",
        "random_state = 87 # remove in next run - added line in cuda cell\n",
        "# train_sampler = RelativePositioningSampler(\n",
        "#     splitted['train'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
        "#     n_examples=n_examples_train, same_rec_neg=True, random_state=random_state)\n",
        "valid_sampler = RelativePositioningSampler(\n",
        "    splitted['valid'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
        "    n_examples=n_examples_valid, same_rec_neg=True, random_state=random_state).presample()\n",
        "test_sampler = RelativePositioningSampler(\n",
        "    splitted['test'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
        "    n_examples=n_examples_test, same_rec_neg=True, random_state=random_state).presample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FaEQ7pcz5NB",
        "outputId": "bc537acc-d55d-4d43-b80a-5436b757084b"
      },
      "source": [
        "print(test_sampler.info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     index                                   i_start_in_trial\n",
            "subject                                                                                                      \n",
            "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "1        [2570, 2571, 2572, 2573, 2574, 2575, 2576, 257...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "2        [5757, 5758, 5759, 5760, 5761, 5762, 5763, 576...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "3        [9062, 9063, 9064, 9065, 9066, 9067, 9068, 906...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "4        [12086, 12087, 12088, 12089, 12090, 12091, 120...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX9veiHOSstT",
        "outputId": "2ceb85e5-02b1-400f-936f-cbbf4b9f60f5"
      },
      "source": [
        "print(train_sampler.info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                     index                                   i_start_in_trial\n",
            "subject                                                                                                      \n",
            "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "1        [1931, 1932, 1933, 1934, 1935, 1936, 1937, 193...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "2        [4398, 4399, 4400, 4401, 4402, 4403, 4404, 440...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "3        [6830, 6831, 6832, 6833, 6834, 6835, 6836, 683...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "4        [8781, 8782, 8783, 8784, 8785, 8786, 8787, 878...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "5        [10988, 10989, 10990, 10991, 10992, 10993, 109...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "6        [13104, 13105, 13106, 13107, 13108, 13109, 131...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "7        [14943, 14944, 14945, 14946, 14947, 14948, 149...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "8        [17079, 17080, 17081, 17082, 17083, 17084, 170...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "9        [19035, 19036, 19037, 19038, 19039, 19040, 190...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "10       [21176, 21177, 21178, 21179, 21180, 21181, 211...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "11       [23034, 23035, 23036, 23037, 23038, 23039, 230...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "12       [25214, 25215, 25216, 25217, 25218, 25219, 252...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "13       [27935, 27936, 27937, 27938, 27939, 27940, 279...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "14       [29956, 29957, 29958, 29959, 29960, 29961, 299...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "15       [31967, 31968, 31969, 31970, 31971, 31972, 319...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "16       [34200, 34201, 34202, 34203, 34204, 34205, 342...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "17       [37261, 37262, 37263, 37264, 37265, 37266, 372...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "18       [39212, 39213, 39214, 39215, 39216, 39217, 392...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "19       [41781, 41782, 41783, 41784, 41785, 41786, 417...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "20       [43696, 43697, 43698, 43699, 43700, 43701, 437...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "21       [45408, 45409, 45410, 45411, 45412, 45413, 454...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "22       [47644, 47645, 47646, 47647, 47648, 47649, 476...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "23       [50110, 50111, 50112, 50113, 50114, 50115, 501...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "24       [52313, 52314, 52315, 52316, 52317, 52318, 523...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "25       [54341, 54342, 54343, 54344, 54345, 54346, 543...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "26       [56078, 56079, 56080, 56081, 56082, 56083, 560...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "27       [59679, 59680, 59681, 59682, 59683, 59684, 596...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "28       [61531, 61532, 61533, 61534, 61535, 61536, 615...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "29       [63928, 63929, 63930, 63931, 63932, 63933, 639...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "30       [67347, 67348, 67349, 67350, 67351, 67352, 673...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "31       [69872, 69873, 69874, 69875, 69876, 69877, 698...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "32       [72056, 72057, 72058, 72059, 72060, 72061, 720...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "33       [74686, 74687, 74688, 74689, 74690, 74691, 746...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "34       [77452, 77453, 77454, 77455, 77456, 77457, 774...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "35       [79826, 79827, 79828, 79829, 79830, 79831, 798...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "36       [82066, 82067, 82068, 82069, 82070, 82071, 820...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "37       [84758, 84759, 84760, 84761, 84762, 84763, 847...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n",
            "38       [87483, 87484, 87485, 87486, 87487, 87488, 874...  [0, 3000, 6000, 9000, 12000, 15000, 18000, 210...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBf_gS3JSxAP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGXrVF9HW_4_"
      },
      "source": [
        "# SleepStagerChambon Training for RP task - Based on [this tutorial](https://braindecode.org/auto_examples/plot_relative_positioning.html#creating-the-model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBuAnK0JTFPB"
      },
      "source": [
        "model = ContrastiveNet(emb, emb_size).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "524f0197ff454d3fb270938d72d19898",
            "f6a398f60dab4d68b5052291dc6782b0",
            "47c1f950d66447e59f679825a4ce5269",
            "3269fd81713449d7b744c65c61527c87",
            "3064251aa31d46e386639a626d645edd",
            "bc90f4c6ab70496bbeeb33a921b5b7ed",
            "e0eb048efdac4a8ca3492d14ffd4a94c",
            "1c59009297114534a781ca4d2c9771a0"
          ]
        },
        "id": "dLXRp8TRK63U",
        "outputId": "d635c373-775b-4ad1-df7a-dd771b247c85"
      },
      "source": [
        "# wandb\n",
        "\n",
        "wandb_run = wandb.init(name = \"RP-SSL SSC2018 train\", project='RP-fulltrain', entity='sleep_hacking')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1onc2be2) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3699<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "524f0197ff454d3fb270938d72d19898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210909_194710-1onc2be2/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210909_194710-1onc2be2/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">RP-SSL SSC2018 train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1onc2be2\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1onc2be2</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1onc2be2). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">RP-SSL SSC2018 train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1qjkb7jt\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1qjkb7jt</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210909_194843-1qjkb7jt</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEwTIYMPrg-F",
        "outputId": "a964860e-8ba7-4eea-ab3e-8599570dce75"
      },
      "source": [
        "\n",
        "# Train the network\n",
        "lr = 5e-2 # 5e-4\n",
        "batch_size = 1024 # increase this next time\n",
        "n_epochs = 150\n",
        "num_workers = 0 # if n_jobs <= 1 else n_jobs\n",
        "\n",
        "# Callback WandbLogger logs the \"best trained model\", etc. after every epoch\n",
        "# Not sure of definition of best trained\n",
        "\n",
        "# TODO - \n",
        "# Add early stopping with 10 on valid_bacc I guess - \n",
        "# This fails if big oscillations happens, but well the lr is low\n",
        "\n",
        "# should make this function of parameters for easiness\n",
        "save_path = \"/content/drive/MyDrive/mne_data/rp_ssc_checkpoints3\" \n",
        "\n",
        "# Log hyperparameters\n",
        "wandb_run.config.update({\"Embedder_size\":emb_size, \"learning rate\": lr, \n",
        "                         \"batch size\": batch_size, \"n_conv_chs_SSC\": n_conv_chs,\n",
        "                         \"tau_pos\":tau_pos, \"tau_neg\":tau_neg, \"n_examples_RPsampler\":n_examples,\n",
        "                         \"n_examples_train\":n_examples_train,\"n_examples_val\":n_examples_valid,\n",
        "                         \"save_path\":save_path})\n",
        "\n",
        "# org paper used a weight decay of 1e-3 on all trainable params\n",
        "cp = Checkpoint(monitor = 'valid_acc_best',\n",
        "                f_params = None, f_optimizer = None, f_criterion = None,\n",
        "                f_pickle = \"model_{last_epoch[epoch]}.pkl\",\n",
        "                dirname = save_path)\n",
        "train_acc = EpochScoring(\n",
        "    scoring='accuracy', on_train=True, name='train_acc',\n",
        "    lower_is_better=False)\n",
        "valid_acc = EpochScoring(\n",
        "    scoring='accuracy', on_train=False, name='valid_acc',\n",
        "    lower_is_better=False)\n",
        "callbacks = [('train_acc', train_acc),\n",
        "             ('valid_acc', valid_acc),\n",
        "             (\"checkpoint\",cp),\n",
        "             (\"wandb\",WandbLogger(wandb_run))\n",
        "             ]\n",
        "\n",
        "\n",
        "clf = EEGClassifier(\n",
        "    model,\n",
        "    criterion=torch.nn.BCEWithLogitsLoss,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    max_epochs=n_epochs,\n",
        "    iterator_train__shuffle=False,\n",
        "    iterator_train__sampler=train_sampler,\n",
        "    iterator_valid__sampler=valid_sampler,\n",
        "    iterator_train__num_workers=num_workers,\n",
        "    iterator_valid__num_workers=num_workers,\n",
        "    train_split=predefined_split(splitted['valid']),\n",
        "    optimizer__lr=lr,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'braindecode.classifier.EEGClassifier'>[uninitialized](\n",
            "  module=ContrastiveNet(\n",
            "    (emb): SleepStagerChambon2018(\n",
            "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "      (feature_extractor): Sequential(\n",
            "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): ReLU()\n",
            "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (fc): Sequential(\n",
            "        (0): Dropout(p=0, inplace=False)\n",
            "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (clf): Sequential(\n",
            "      (0): Dropout(p=0.5, inplace=False)\n",
            "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
            "    )\n",
            "  ),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQApBC7tGL5N"
      },
      "source": [
        "Classifier Fit for 2k pairs, batch_size 1024 with increased learning rate 5e-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ4DkFiDGR2a",
        "outputId": "1aa4b870-ff25-4cf3-f66e-e989186aedb1"
      },
      "source": [
        "# del clf\n",
        "mne.set_log_level(True)\n",
        "clf.fit(splitted[\"train\"], y=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp       dur\n",
            "-------  -----------  ------------  -----------  ------------  ----  --------\n",
            "      1       \u001b[36m0.7347\u001b[0m        \u001b[32m0.7485\u001b[0m       \u001b[35m0.5259\u001b[0m        \u001b[31m1.0389\u001b[0m     +  442.1357\n",
            "      2       \u001b[36m0.8034\u001b[0m        \u001b[32m0.4372\u001b[0m       0.5228        1.5883        447.0001\n",
            "      3       \u001b[36m0.8240\u001b[0m        \u001b[32m0.4050\u001b[0m       \u001b[35m0.5264\u001b[0m        1.3782     +  449.5075\n",
            "      4       \u001b[36m0.8276\u001b[0m        \u001b[32m0.3979\u001b[0m       0.5230        1.5310        447.5935\n",
            "      5       \u001b[36m0.8350\u001b[0m        \u001b[32m0.3818\u001b[0m       \u001b[35m0.5302\u001b[0m        1.4573     +  444.6362\n",
            "      6       \u001b[36m0.8394\u001b[0m        \u001b[32m0.3742\u001b[0m       0.5268        1.4676        446.8178\n",
            "      7       \u001b[36m0.8441\u001b[0m        \u001b[32m0.3635\u001b[0m       0.5222        1.9785        443.0689\n",
            "      8       \u001b[36m0.8563\u001b[0m        \u001b[32m0.3435\u001b[0m       \u001b[35m0.5331\u001b[0m        1.4493     +  443.6451\n",
            "      9       \u001b[36m0.8589\u001b[0m        \u001b[32m0.3374\u001b[0m       \u001b[35m0.5337\u001b[0m        1.4687     +  445.8946\n",
            "     10       \u001b[36m0.8604\u001b[0m        \u001b[32m0.3368\u001b[0m       0.5218        2.0681        446.5974\n",
            "     11       \u001b[36m0.8647\u001b[0m        \u001b[32m0.3302\u001b[0m       0.5303        1.4414        443.9837\n",
            "     12       \u001b[36m0.8663\u001b[0m        \u001b[32m0.3236\u001b[0m       0.5236        2.0221        443.2359\n",
            "     13       \u001b[36m0.8697\u001b[0m        \u001b[32m0.3184\u001b[0m       0.5296        1.9290        442.3721\n",
            "     14       \u001b[36m0.8720\u001b[0m        \u001b[32m0.3155\u001b[0m       0.5234        2.2346        443.6867\n",
            "     15       \u001b[36m0.8732\u001b[0m        \u001b[32m0.3105\u001b[0m       0.5177        2.7112        443.4497\n",
            "     16       \u001b[36m0.8738\u001b[0m        0.3112       \u001b[35m0.5366\u001b[0m        1.5007     +  445.0317\n",
            "     17       \u001b[36m0.8759\u001b[0m        \u001b[32m0.3059\u001b[0m       0.5277        2.2512        445.0952\n",
            "     18       \u001b[36m0.8776\u001b[0m        \u001b[32m0.3035\u001b[0m       0.5215        2.4040        443.6452\n",
            "     19       0.8772        \u001b[32m0.3034\u001b[0m       0.5287        2.1504        443.3725\n",
            "     20       0.8770        0.3043       0.5260        1.9407        441.2250\n",
            "     21       0.8765        0.3052       0.5271        2.1013        440.4789\n",
            "     22       0.8761        0.3050       0.5318        1.5802        443.1225\n",
            "     23       0.8765        0.3050       0.5242        2.3746        444.2671\n",
            "     24       \u001b[36m0.8809\u001b[0m        \u001b[32m0.2984\u001b[0m       0.5299        1.8940        447.4598\n",
            "     25       0.8768        0.3055       0.5216        2.4053        450.0561\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=ContrastiveNet(\n",
              "    (emb): SleepStagerChambon2018(\n",
              "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
              "      (feature_extractor): Sequential(\n",
              "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): ReLU()\n",
              "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (fc): Sequential(\n",
              "        (0): Dropout(p=0, inplace=False)\n",
              "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (clf): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
              "    )\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr7jZrsaHENr"
      },
      "source": [
        "with open(save_path+'/final_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9EErwXeHQxI",
        "outputId": "c180138b-5672-4253-e7c0-c9ff468ec755"
      },
      "source": [
        "# Use the val itself to see the matrix\n",
        "y_pred = clf.forward(splitted['valid'], training=False) > 0\n",
        "\n",
        "y_true = [y for _, _, y in valid_sampler]\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5156  765]\n",
            " [4997 1082]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.51      0.87      0.64      5921\n",
            "         1.0       0.59      0.18      0.27      6079\n",
            "\n",
            "    accuracy                           0.52     12000\n",
            "   macro avg       0.55      0.52      0.46     12000\n",
            "weighted avg       0.55      0.52      0.45     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676,
          "referenced_widgets": [
            "6891eba80d574414b2b26dc55dcbd1e7",
            "6c9e817db71e47938e8b555f7f1a6af7",
            "b595e8a392e64aed9443e828978633da",
            "a98440f6971a4233aa4881513b7e9c58",
            "072165fd82d945ec92e348770afade68",
            "4061eb1eddc941f6bc6b435220beef31",
            "020f615c3fd14cfe9fc995619fa3af22",
            "f41b4b022d0b4cf199de917edd16125d"
          ]
        },
        "id": "u1ZQvFyXyisb",
        "outputId": "0a6cca59-ee2f-4b24-a96e-5d52d33dbe15"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3759<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6891eba80d574414b2b26dc55dcbd1e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210909_194843-1qjkb7jt/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210909_194843-1qjkb7jt/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>dur</td><td>450.05605</td></tr><tr><td>train_loss</td><td>0.30546</td></tr><tr><td>valid_loss</td><td>2.40528</td></tr><tr><td>train_acc</td><td>0.87683</td></tr><tr><td>valid_acc</td><td>0.52158</td></tr><tr><td>_runtime</td><td>11278</td></tr><tr><td>_timestamp</td><td>1631228205</td></tr><tr><td>_step</td><td>24</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>dur</td><td>▂▆█▆▄▆▃▃▅▅▄▃▂▃▃▄▄▃▃▂▁▃▄▆█</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▁▃▂▃▃▃▅▃▃▅▃▅▅▆█▃▆▇▆▅▅▃▇▅▇</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇████████████</td></tr><tr><td>valid_acc</td><td>▄▃▄▃▆▄▃▇▇▃▆▃▅▃▁█▅▂▅▄▄▆▃▆▂</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">RP-SSL SSC2018 train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1qjkb7jt\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1qjkb7jt</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36TDjBbbTrib"
      },
      "source": [
        "# Other SSL-CNN training tries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMg7CXbS60BN"
      },
      "source": [
        "Classifier Fit for 2k pairs, batch_size 1024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V446vga86ztM",
        "outputId": "4b3426a8-2105-4c40-cc06-12802390b54a"
      },
      "source": [
        "# del clf\n",
        "mne.set_log_level(True)\n",
        "clf.fit(splitted[\"train\"], y=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp       dur\n",
            "-------  -----------  ------------  -----------  ------------  ----  --------\n",
            "      1       \u001b[36m0.8249\u001b[0m        \u001b[32m0.4070\u001b[0m       \u001b[35m0.5135\u001b[0m        \u001b[31m1.5999\u001b[0m     +  451.3815\n",
            "      2       \u001b[36m0.8299\u001b[0m        \u001b[32m0.4006\u001b[0m       0.5111        1.6242        445.3153\n",
            "      3       \u001b[36m0.8359\u001b[0m        \u001b[32m0.3893\u001b[0m       0.5129        1.6680        443.0258\n",
            "      4       \u001b[36m0.8391\u001b[0m        \u001b[32m0.3824\u001b[0m       0.5108        1.8031        442.6547\n",
            "      5       \u001b[36m0.8429\u001b[0m        \u001b[32m0.3756\u001b[0m       0.5122        1.7254        443.6592\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=ContrastiveNet(\n",
              "    (emb): SleepStagerChambon2018(\n",
              "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
              "      (feature_extractor): Sequential(\n",
              "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): ReLU()\n",
              "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (fc): Sequential(\n",
              "        (0): Dropout(p=0, inplace=False)\n",
              "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (clf): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
              "    )\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKTEnjE8IWH"
      },
      "source": [
        "with open('/content/drive/MyDrive/mne_data/rp_ssc_checkpoints2/final_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzlesU-CF2Qn",
        "outputId": "c54bb17e-0647-4f13-8fb1-9d3e679b64cd"
      },
      "source": [
        "# Use the val itself to see the matrix\n",
        "y_pred = clf.forward(splitted['valid'], training=False) > 0\n",
        "\n",
        "y_true = [y for _, _, y in valid_sampler]\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4626 1295]\n",
            " [4540 1539]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.78      0.61      5921\n",
            "         1.0       0.54      0.25      0.35      6079\n",
            "\n",
            "    accuracy                           0.51     12000\n",
            "   macro avg       0.52      0.52      0.48     12000\n",
            "weighted avg       0.52      0.51      0.48     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcVehMzmEKIg"
      },
      "source": [
        "Probably should try increasing the learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXovG350wcE"
      },
      "source": [
        "Classifier Fit for 2000 pairs in RP Sampler and batch_size 256\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSt54MCru7-L",
        "outputId": "937184c0-995a-4788-d3b4-e8141cf0ff2c"
      },
      "source": [
        "mne.set_log_level(True)\n",
        "clf.fit(splitted[\"train\"], y=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp       dur\n",
            "-------  -----------  ------------  -----------  ------------  ----  --------\n",
            "      1       \u001b[36m0.7621\u001b[0m        \u001b[32m0.4982\u001b[0m       \u001b[35m0.5065\u001b[0m        \u001b[31m1.6180\u001b[0m     +  448.4228\n",
            "      2       \u001b[36m0.8071\u001b[0m        \u001b[32m0.4340\u001b[0m       \u001b[35m0.5132\u001b[0m        1.7131     +  453.6100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=ContrastiveNet(\n",
              "    (emb): SleepStagerChambon2018(\n",
              "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
              "      (feature_extractor): Sequential(\n",
              "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): ReLU()\n",
              "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (fc): Sequential(\n",
              "        (0): Dropout(p=0, inplace=False)\n",
              "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (clf): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
              "    )\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA58WPYt67vY",
        "outputId": "d0ddee62-c144-455c-f9a7-06ced4a85998"
      },
      "source": [
        "# Use the val itself to see the matrix\n",
        "y_pred = clf.forward(splitted['valid'], training=False) > 0\n",
        "\n",
        "y_true = [y for _, _, y in valid_sampler]\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4385 1536]\n",
            " [4299 1780]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.74      0.60      5921\n",
            "         1.0       0.54      0.29      0.38      6079\n",
            "\n",
            "    accuracy                           0.51     12000\n",
            "   macro avg       0.52      0.52      0.49     12000\n",
            "weighted avg       0.52      0.51      0.49     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3DvBAn0rLv"
      },
      "source": [
        "Classifier Fitting Table for 250 pairs in RP sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOXW2FSYtZnT",
        "outputId": "cf293aab-066c-4938-dbf4-08ab7b4f8baf"
      },
      "source": [
        "# Model training for a specified number of epochs. `y` is None as it is already\n",
        "# supplied in the dataset.\n",
        "# The idotic thing doesn't even seem to get converted to tensor or gpu.. idk\n",
        "# It's loading everything at the sampler, even though everything should be in memory\n",
        "# See if the data instead of me\n",
        "# Memory access is within couple of seconds when preload is done \n",
        "# still not sure if the tensor conversion can be activated at a point before the dataloader\n",
        "# Follow up with an issue citing this - https://github.com/braindecode/braindecode/issues/63#issuecomment-584035555 \n",
        "# Checked the follow up PRs, etc. Didn't see any discussion regarding this tensor cast clearly\n",
        "mne.set_log_level(True)\n",
        "clf.fit(splitted[\"train\"], y=None)\n",
        "# clf.load_params(checkpoint=cp)  # Load the model with the lowest valid_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing optimizer because the following parameters were re-set: lr.\n",
            "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
            "-------  -----------  ------------  -----------  ------------  ----  -------\n",
            "      1       \u001b[36m0.7188\u001b[0m        \u001b[32m0.5638\u001b[0m       \u001b[35m0.4967\u001b[0m        \u001b[31m1.1182\u001b[0m     +  52.8966\n",
            "      2       \u001b[36m0.7631\u001b[0m        \u001b[32m0.5085\u001b[0m       \u001b[35m0.5080\u001b[0m        1.2368     +  55.3495\n",
            "      3       \u001b[36m0.7839\u001b[0m        \u001b[32m0.4825\u001b[0m       0.5053        1.2735        56.1307\n",
            "      4       \u001b[36m0.7876\u001b[0m        \u001b[32m0.4672\u001b[0m       0.5000        1.4313        52.9659\n",
            "      5       \u001b[36m0.8000\u001b[0m        \u001b[32m0.4534\u001b[0m       0.5013        1.4262        53.1660\n",
            "      6       0.7941        0.4584       0.4980        1.3995        52.8803\n",
            "      7       0.7947        0.4596       0.4987        1.5176        53.0050\n",
            "      8       0.7988        \u001b[32m0.4489\u001b[0m       0.4993        1.4433        53.6070\n",
            "      9       \u001b[36m0.8022\u001b[0m        0.4492       0.4960        1.5992        53.4039\n",
            "     10       0.7984        \u001b[32m0.4450\u001b[0m       0.5033        1.5640        52.8671\n",
            "     11       \u001b[36m0.8138\u001b[0m        \u001b[32m0.4303\u001b[0m       0.5007        1.5514        53.2484\n",
            "     12       0.8039        0.4422       0.5020        1.6311        53.3155\n",
            "     13       0.8052        0.4416       0.4987        1.4475        52.8492\n",
            "     14       0.8136        \u001b[32m0.4270\u001b[0m       \u001b[35m0.5087\u001b[0m        1.7229     +  52.9190\n",
            "     15       0.8023        0.4415       0.5040        1.3678        55.4407\n",
            "     16       \u001b[36m0.8157\u001b[0m        \u001b[32m0.4240\u001b[0m       0.5047        1.6113        52.7655\n",
            "     17       0.8134        0.4284       0.5060        1.4201        52.9041\n",
            "     18       0.8127        0.4278       0.5033        1.6026        52.7816\n",
            "     19       \u001b[36m0.8197\u001b[0m        \u001b[32m0.4155\u001b[0m       0.5060        1.5683        52.8885\n",
            "     20       \u001b[36m0.8287\u001b[0m        \u001b[32m0.4027\u001b[0m       0.5047        1.7777        53.1812\n",
            "     21       0.8159        0.4193       0.5067        1.6773        52.9821\n",
            "     22       0.8130        0.4154       \u001b[35m0.5093\u001b[0m        1.7015     +  52.8629\n",
            "     23       0.8242        0.4104       0.5087        1.6124        54.9080\n",
            "     24       0.8214        0.4158       \u001b[35m0.5133\u001b[0m        1.5872     +  53.0399\n",
            "     25       0.8233        0.4117       0.5067        1.6238        55.7775\n",
            "     26       0.8230        0.4083       0.5113        1.8453        52.8557\n",
            "     27       0.8173        0.4144       0.5113        1.5662        53.2306\n",
            "     28       \u001b[36m0.8336\u001b[0m        \u001b[32m0.3955\u001b[0m       0.5107        1.6262        53.1925\n",
            "     29       0.8245        0.4047       0.5127        1.6455        53.0099\n",
            "     30       0.8161        0.4146       \u001b[35m0.5153\u001b[0m        1.5901     +  53.0080\n",
            "     31       0.8266        0.4009       0.5140        1.6412        55.1981\n",
            "     32       0.8296        \u001b[32m0.3955\u001b[0m       0.5153        1.6446        53.0208\n",
            "     33       \u001b[36m0.8378\u001b[0m        \u001b[32m0.3849\u001b[0m       0.5127        1.8075        53.2272\n",
            "     34       0.8296        0.3925       \u001b[35m0.5207\u001b[0m        1.8774     +  52.7477\n",
            "     35       0.8291        0.3989       0.5133        1.6835        55.6553\n",
            "     36       \u001b[36m0.8410\u001b[0m        \u001b[32m0.3812\u001b[0m       0.5160        1.6808        52.8202\n",
            "     37       0.8292        0.3971       0.5133        1.7537        52.6179\n",
            "     38       0.8327        0.3931       0.5187        1.6751        53.0450\n",
            "     39       0.8323        0.3929       0.5133        1.7129        52.6427\n",
            "     40       0.8382        \u001b[32m0.3811\u001b[0m       \u001b[35m0.5213\u001b[0m        1.6249     +  52.8640\n",
            "     41       0.8347        0.3934       0.5127        1.6516        55.8448\n",
            "     42       0.8373        0.3892       0.5147        1.5068        52.5313\n",
            "     43       0.8351        0.3847       0.5133        1.8623        53.0864\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=ContrastiveNet(\n",
              "    (emb): SleepStagerChambon2018(\n",
              "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
              "      (feature_extractor): Sequential(\n",
              "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): ReLU()\n",
              "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (fc): Sequential(\n",
              "        (0): Dropout(p=0, inplace=False)\n",
              "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (clf): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
              "    )\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYGmmwrvAd7T"
      },
      "source": [
        "# Save last model - Likely that if it isn't already checkpointed, it's probably overfitted\n",
        "# Still save it I guess\n",
        "# Also check if wandb is auto logging the checkpointed, final\n",
        "with open('/content/drive/MyDrive/mne_data/rp_ssc_checkpoints2/final_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f) # I think I've saved the wrong one previously"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADrU0AjfsAEV"
      },
      "source": [
        "# training_viz(clf)\n",
        "# wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkPQMB3UsMSw",
        "outputId": "a98bb0ef-e294-4ecf-8c2b-ba02ca591688"
      },
      "source": [
        "# Switch to the test sampler\n",
        "# clf.iterator_valid__sampler = test_sampler\n",
        "\n",
        "# wandb got closed, so disabling wandb callback\n",
        "# clf.set_params(callbacks=\"disable\")\n",
        "\n",
        "# Use the val itself to see the matrix\n",
        "y_pred = clf.forward(splitted['valid'], training=False) > 0\n",
        "\n",
        "y_true = [y for _, _, y in valid_sampler]\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[575 166]\n",
            " [556 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.51      0.78      0.61       741\n",
            "         1.0       0.55      0.27      0.36       759\n",
            "\n",
            "    accuracy                           0.52      1500\n",
            "   macro avg       0.53      0.52      0.49      1500\n",
            "weighted avg       0.53      0.52      0.49      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "ac7a3a89798e4bfb963ed01afa9df1f0",
            "c399fb3468c74814bb3e2a82ff47f6f4",
            "91878d9faaa94a829f494a0cd0069a1c",
            "d98dee6562364ee1b59a7ab394bb3236",
            "e1beec42903f451f8d149f69a6f810ec",
            "cc071bfa728a47ba9b0983dc2ce2fac8",
            "405c7db10a5647378c62741431eb99df",
            "c23818da57394ea39f71d947c146a9c1"
          ]
        },
        "id": "Zvg9gsxiLSoQ",
        "outputId": "9020d5b6-3241-4ca4-e3e5-a7dbeb68bea5"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2246<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac7a3a89798e4bfb963ed01afa9df1f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210909_152826-xvoe3b0h/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210909_152826-xvoe3b0h/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">RP-SSL SSC2018 train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/xvoe3b0h\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/xvoe3b0h</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi1ldLSnYlQl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DOn7lfOsZaN"
      },
      "source": [
        "# Use the CNN as Feature Extractor and train the actual Sleep Stage Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PFffmN40-jh",
        "outputId": "6fe361cc-6fe9-4867-8d3a-e4b1240358c4"
      },
      "source": [
        "print(emb)\n",
        "print(clf.module.emb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SleepStagerChambon2018(\n",
            "  (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0, inplace=False)\n",
            "    (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "SleepStagerChambon2018(\n",
            "  (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0, inplace=False)\n",
            "    (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hZR5IDL0k-"
      },
      "source": [
        "# Load the CNN\n",
        "# rp_ssc_checkpoints3 (2k, 1024, inc LR)\n",
        "# rp_ssc_checkpoints2 (2k, 1024)\n",
        "# rp_ssc_checkpoints2k_256 (2k, 256)\n",
        "# rp_ssc_checkpoints (250, 256)\n",
        "def load_obj(path,name):\n",
        "    with open(path + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Need the trained embedder not the classifier with the contrastive model\n",
        "emb_c = clf.module.emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEaehqj3seTD"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Extract features with the trained embedder\n",
        "data = dict()\n",
        "# splitted has the RPDataset \n",
        "# For unlabelled a simple dataset should be equivalent since single win\n",
        "for name, split in splitted.items():\n",
        "    # run the till the RP sampler above\n",
        "    split.return_pair = False  # Return single windows\n",
        "    loader = DataLoader(split, batch_size=batch_size, num_workers=num_workers)\n",
        "    with torch.no_grad():\n",
        "        feats = [emb_c(batch_x.to(device)).cpu().numpy()\n",
        "                 for batch_x, _, _ in loader]\n",
        "    data[name] = (np.concatenate(feats), split.get_metadata()['target'].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLMJXe6e47lt",
        "outputId": "7f54de85-6eb1-40fa-d116-7a3d63fc852d"
      },
      "source": [
        "print(data.keys())\n",
        "print(len(data[\"train\"]))\n",
        "\n",
        "print(data[\"train\"][0].shape)\n",
        "print(data[\"train\"][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'valid'])\n",
            "2\n",
            "(90545, 100)\n",
            "(90545,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-xQrmG1C8vu"
      },
      "source": [
        "Saving the data from the model at the end of the last embedder trained (2k pairs, 1024 batch_size for 25 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8dyTUrOAiE9"
      },
      "source": [
        "# Save data - Then simple load for next time\n",
        "save_path = \"/content/drive/MyDrive/mne_data/RPClassifier/\" \n",
        "with open(save_path+'Data_Dict.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Too lazy to convert to csv and save\n",
        "# Just load data and train the classifier\n",
        "def load_obj(path,name):\n",
        "    with open(path + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "name = \"Data_Dict\"\n",
        "data2 = load_obj(save_path,name)\n",
        "# For unlabelled dataset alone you need to reload the embedder\n",
        "\n",
        "# Might also have to try SSL training the model itself on the validation data\n",
        "# either new one or using the same net and just continuing the training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNRuKJQxCT9N",
        "outputId": "13a68ee3-95a4-4a37-f659-6866d0558214"
      },
      "source": [
        "print(data2.keys())\n",
        "print(len(data2[\"train\"]))\n",
        "\n",
        "print(data2[\"train\"][0].shape)\n",
        "print(data2[\"train\"][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'valid'])\n",
            "2\n",
            "(90545, 100)\n",
            "(90545,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InHOZKUvCYQk"
      },
      "source": [
        "# For loading from next time\n",
        "data = data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vFWV5E3Ce96"
      },
      "source": [
        "Have to try different Sklearn Classifiers (Could run Auto-Sklearn also I guess)\n",
        "\n",
        "Also should probably try a wandb search space atleast now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtdvYZ0zAeXH"
      },
      "source": [
        "newton-cg with max-iter 1.5k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "3qkhvttL_P-_",
        "outputId": "7011da89-a647-4d44-eeee-fba8a2b9df98"
      },
      "source": [
        "# wandb for the classifier - same project diff name should be fine\n",
        "wandb_run = wandb.init(name = \"Classifier train\", project='RP-fulltrain', entity='sleep_hacking')\n",
        "max_iter = 1500\n",
        "solver = \"newton-cg\"\n",
        "wandb.config.update({'classifier type':'log_reg','solver':solver,\"max_iter\":max_iter})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1kaaa2oy) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1579, in _atexit_cleanup\n",
            "    self._on_finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1715, in _on_finish\n",
            "    self.history._flush()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
            "    self._callback(row=self._data, step=self._step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 903, in _history_callback\n",
            "    row, step, publish_step=not_using_tensorboard\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\", line 223, in publish_history\n",
            "    item.value_json = json_dumps_safer_history(v)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/util.py\", line 749, in json_dumps_safer_history\n",
            "    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)\n",
            "  File \"/usr/lib/python3.7/json/__init__.py\", line 238, in dumps\n",
            "    **kw).encode(obj)\n",
            "  File \"/usr/lib/python3.7/json/encoder.py\", line 199, in encode\n",
            "    chunks = self.iterencode(o, _one_shot=True)\n",
            "  File \"/usr/lib/python3.7/json/encoder.py\", line 257, in iterencode\n",
            "    return _iterencode(o, 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/util.py\", line 716, in default\n",
            "    return json.JSONEncoder.default(self, obj)\n",
            "  File \"/usr/lib/python3.7/json/encoder.py\", line 179, in default\n",
            "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
            "TypeError: Object of type Pipeline is not JSON serializable\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1kaaa2oy). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">Classifier train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3blxmbfg\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3blxmbfg</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210909_235848-3blxmbfg</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrHGjUuG_UlZ"
      },
      "source": [
        "# max_iter = 1500\n",
        "# solver = \"newton-cg\"\n",
        "log_reg = LogisticRegression(\n",
        "    penalty='l2', C=1.0, class_weight='balanced', solver=solver,\n",
        "    multi_class='multinomial', random_state=random_state,verbose=1,\n",
        "    n_jobs=-1,max_iter=max_iter)\n",
        "clf_pipe = make_pipeline(StandardScaler(), log_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqZfQfCb_v5H",
        "outputId": "81ce5f63-8c7c-4acb-995c-db1165025ae6"
      },
      "source": [
        "s = t()\n",
        "clf_pipe.fit(*data['train'])\n",
        "e = t()\n",
        "print(f\"Fit time {e-s}\")\n",
        "\n",
        "train_y_pred = clf_pipe.predict(data['train'][0])\n",
        "train_bal_acc = balanced_accuracy_score(data['train'][1], train_y_pred)\n",
        "print(f'Train bal acc: {train_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": train_bal_acc})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.2min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fit time 131.59850764274597\n",
            "Train bal acc: 0.6739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv6HVDRNAQrf",
        "outputId": "d25eebf8-6b1a-4e7e-8113-4f26e39af6b2"
      },
      "source": [
        "valid_y_pred = clf_pipe.predict(data['valid'][0])\n",
        "valid_bal_acc = balanced_accuracy_score(data['valid'][1], valid_y_pred)\n",
        "wandb.log({\"Val bal Acc\":valid_bal_acc})\n",
        "# print('Sleep staging performance with logistic regression:')\n",
        "print(f'Valid bal acc: {valid_bal_acc:0.4f}')\n",
        "\n",
        "print('Results on test set:')\n",
        "print(confusion_matrix(data['valid'][1], valid_y_pred))\n",
        "print(classification_report(data['valid'][1], valid_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['valid'][1], valid_y_pred)\n",
        "# wandb run end \n",
        "# wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid bal acc: 0.5592\n",
            "Results on test set:\n",
            "[[4558  921   26   25   25  455]\n",
            " [ 171  956  251   25    1  268]\n",
            " [  20 1011 2907  576   37  484]\n",
            " [   0   15  166  429   86    8]\n",
            " [   0    0   15  243  154    2]\n",
            " [  77  649  132    0    0  749]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.76      0.84      6010\n",
            "           1       0.27      0.57      0.37      1672\n",
            "           2       0.83      0.58      0.68      5035\n",
            "           3       0.33      0.61      0.43       704\n",
            "           4       0.51      0.37      0.43       414\n",
            "           5       0.38      0.47      0.42      1607\n",
            "\n",
            "    accuracy                           0.63     15442\n",
            "   macro avg       0.54      0.56      0.53     15442\n",
            "weighted avg       0.74      0.63      0.66     15442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HluVmAaeAVOP"
      },
      "source": [
        "# Save the model, also log to wandb I guess\n",
        "save_path = \"/content/drive/MyDrive/mne_data/RPClassifier/\" \n",
        "with open(save_path+'LogReg_newton-cg_1500.pkl', 'wb') as f:\n",
        "    pickle.dump(clf_pipe, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "e5c20cbe211146deb533adb4e34356b4",
            "feca487d6fe84bc8a09f8573ede48507",
            "469ea3599e36417aa4aa218bca7fd18b",
            "77cdc9e1105b425ba8801586bbefbb5a",
            "ce4c2423c53e47cb99f631525716572d",
            "7a33fc555e0a4d9a94b54fb89fad25b5",
            "f9d65bb0e40145468b51f38330ef8cd3",
            "afc9da7d0362468d90b856457eb7bc88"
          ]
        },
        "id": "fkDSQWd0DQnY",
        "outputId": "8474f1a1-6ba0-4e29-8d54-f8ffc792ffd0"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 5610<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5c20cbe211146deb533adb4e34356b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210909_235848-3blxmbfg/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210909_235848-3blxmbfg/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>0.67393</td></tr><tr><td>_runtime</td><td>190</td></tr><tr><td>_timestamp</td><td>1631232121</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>Val bal Acc</td><td>0.55916</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁██</td></tr><tr><td>_timestamp</td><td>▁██</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>Val bal Acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">Classifier train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3blxmbfg\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3blxmbfg</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58eG8JaBIOU6"
      },
      "source": [
        "# Predict on unlabelled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujxym1ej75P0"
      },
      "source": [
        "newton-cg solver - failed to converge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "9NFjTPA07sRp",
        "outputId": "918ac084-e529-44ed-b915-7c1befed1295"
      },
      "source": [
        "# wandb for the classifier - same project diff name should be fine\n",
        "wandb_run = wandb.init(name = \"Classifier train\", project='RP-fulltrain', entity='sleep_hacking')\n",
        "max_iter = 100\n",
        "wandb.config.update({'classifier type':'log_reg','solver':\"newton-cg\",\"max_iter\":max_iter})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">Classifier train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1kaaa2oy\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1kaaa2oy</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210909_234017-1kaaa2oy</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvragq0S4djf"
      },
      "source": [
        "# wandb.sklearn.plot_class_proportions()\n",
        "# Initialize the logistic regression model\n",
        "# penalty = 'l2'\n",
        "# C = 1.0\n",
        "# class_weight = 'balanced'\n",
        "# solver = 'saga'\n",
        "log_reg = LogisticRegression(\n",
        "    penalty='l2', C=1.0, class_weight='balanced', solver='newton-cg',\n",
        "    multi_class='multinomial', random_state=random_state)\n",
        "clf_pipe = make_pipeline(StandardScaler(), log_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkLaRgDZ71Rd",
        "outputId": "bb3a7d83-619b-440e-9980-e20649f2d9ba"
      },
      "source": [
        "# Fit and score the logistic regression\n",
        "s = t()\n",
        "clf_pipe.fit(*data['train'])\n",
        "e = t()\n",
        "print(f\"Fit time {e-s}\")\n",
        "\n",
        "train_y_pred = clf_pipe.predict(data['train'][0])\n",
        "train_bal_acc = balanced_accuracy_score(data['train'][1], train_y_pred)\n",
        "print(f'Train bal acc: {train_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": train_bal_acc})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fit time 131.3616509437561\n",
            "Train bal acc: 0.6739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqo4EtfS74bU",
        "outputId": "31283ba1-7f8b-47d6-b60e-1985767c4d24"
      },
      "source": [
        "valid_y_pred = clf_pipe.predict(data['valid'][0])\n",
        "valid_bal_acc = balanced_accuracy_score(data['valid'][1], valid_y_pred)\n",
        "wandb.log({\"Val bal Acc\":valid_bal_acc})\n",
        "# print('Sleep staging performance with logistic regression:')\n",
        "print(f'Valid bal acc: {valid_bal_acc:0.4f}')\n",
        "\n",
        "print('Results on test set:')\n",
        "print(confusion_matrix(data['valid'][1], valid_y_pred))\n",
        "print(classification_report(data['valid'][1], valid_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['valid'][1], valid_y_pred)\n",
        "# wandb run end \n",
        "# wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid bal acc: 0.5592\n",
            "Results on test set:\n",
            "[[4558  921   26   25   25  455]\n",
            " [ 171  956  251   25    1  268]\n",
            " [  20 1011 2907  576   37  484]\n",
            " [   0   15  166  429   86    8]\n",
            " [   0    0   15  243  154    2]\n",
            " [  77  649  132    0    0  749]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.76      0.84      6010\n",
            "           1       0.27      0.57      0.37      1672\n",
            "           2       0.83      0.58      0.68      5035\n",
            "           3       0.33      0.61      0.43       704\n",
            "           4       0.51      0.37      0.43       414\n",
            "           5       0.38      0.47      0.42      1607\n",
            "\n",
            "    accuracy                           0.63     15442\n",
            "   macro avg       0.54      0.56      0.53     15442\n",
            "weighted avg       0.74      0.63      0.66     15442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7xh_e_58yQt"
      },
      "source": [
        "# Save the model, also log to wandb I guess\n",
        "save_path = \"/content/drive/MyDrive/mne_data/RPClassifier\" \n",
        "with open(save_path+'/LogReg_newton-cg.pkl', 'wb') as f:\n",
        "    pickle.dump(clf_pipe, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22PaztFC-Jal"
      },
      "source": [
        "# wandb.log({\"fitted classifier\":clf_pipe})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuek9vXk7714"
      },
      "source": [
        "saga solver - failed to converge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wek3Zx8m-CLW"
      },
      "source": [
        "# wandb for the classifier - same project diff name should be fine\n",
        "wandb_run = wandb.init(name = \"Classifier train\", project='RP-fulltrain', entity='sleep_hacking')\n",
        "\n",
        "wandb.config.update({'classifier type':'log_reg','solver':\"saga\"})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAQAj-hW-Eva"
      },
      "source": [
        "log_reg = LogisticRegression(\n",
        "    penalty='l2', C=1.0, class_weight='balanced', solver='saga',\n",
        "    multi_class='multinomial', random_state=random_state,verbose=1,n_jobs=-1)\n",
        "clf_pipe = make_pipeline(StandardScaler(), log_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41MTToj-3307",
        "outputId": "06f1d948-367d-4bcc-b4d1-7d01c521d084"
      },
      "source": [
        "# Fit and score the logistic regression\n",
        "s = t()\n",
        "clf_pipe.fit(*data['train'])\n",
        "e = t()\n",
        "print(f\"Fit time {e-s}\")\n",
        "\n",
        "train_y_pred = clf_pipe.predict(data['train'][0])\n",
        "train_bal_acc = balanced_accuracy_score(data['train'][1], train_y_pred)\n",
        "print(f'Train bal acc: {train_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": train_bal_acc})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fit time 39.08369469642639\n",
            "Train bal acc: 0.6729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941,
          "referenced_widgets": [
            "9d3abd54fae046e29e887f0ae6e9eab4",
            "ee3aa65400be47cca5e1c0a0495b6b43",
            "db666bdb375946ce834b94b6a40e899e",
            "bb7eea0421764d8fb709c3525afaee3c",
            "a75e9a8118974e9b9e33250cc097f129",
            "3d7f641a1cfc4b6389d3c7f51caec85a",
            "90ac8acd6c34418293b0022ce2093b8b",
            "d986525ebc424bce924499a0df44858a"
          ]
        },
        "id": "f563j3n013gv",
        "outputId": "08a5a58a-3eef-4a1c-f58a-1bd8c02f595b"
      },
      "source": [
        "valid_y_pred = clf_pipe.predict(data['valid'][0])\n",
        "valid_bal_acc = balanced_accuracy_score(data['valid'][1], valid_y_pred)\n",
        "wandb.log({\"Val bal Acc\":valid_bal_acc})\n",
        "# print('Sleep staging performance with logistic regression:')\n",
        "print(f'Valid bal acc: {valid_bal_acc:0.4f}')\n",
        "\n",
        "print('Results on test set:')\n",
        "print(confusion_matrix(data['valid'][1], valid_y_pred))\n",
        "print(classification_report(data['valid'][1], valid_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['valid'][1], valid_y_pred)\n",
        "# wandb run end \n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid bal acc: 0.5611\n",
            "Results on test set:\n",
            "[[4559  922   27   24   25  453]\n",
            " [ 171  962  247   27    1  264]\n",
            " [  20 1004 2909  571   36  495]\n",
            " [   0   14  168  432   83    7]\n",
            " [   0    0   15  242  155    2]\n",
            " [  77  648  132    0    0  750]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.76      0.84      6010\n",
            "           1       0.27      0.58      0.37      1672\n",
            "           2       0.83      0.58      0.68      5035\n",
            "           3       0.33      0.61      0.43       704\n",
            "           4       0.52      0.37      0.43       414\n",
            "           5       0.38      0.47      0.42      1607\n",
            "\n",
            "    accuracy                           0.63     15442\n",
            "   macro avg       0.55      0.56      0.53     15442\n",
            "weighted avg       0.74      0.63      0.66     15442\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 5117<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3abd54fae046e29e887f0ae6e9eab4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210909_232506-2elng8od/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210909_232506-2elng8od/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>0.67295</td></tr><tr><td>_runtime</td><td>779</td></tr><tr><td>_timestamp</td><td>1631230685</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>Val bal Acc</td><td>0.56107</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁██</td></tr><tr><td>_timestamp</td><td>▁██</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>Val bal Acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">Classifier train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/2elng8od\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/2elng8od</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxkKp708PK9"
      },
      "source": [
        "# forgot to save the classifer - Takes very less time, might as well run again\n",
        "with open(save_path+'/final_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXNb-uGy1Pkm"
      },
      "source": [
        "# run for test - unlabelled data - Have to do the embedding for it also\n",
        "\n",
        "# split must be of RP dataset class\n",
        "# loader = DataLoader(split, batch_size=batch_size, num_workers=num_workers)\n",
        "#     with torch.no_grad():\n",
        "#         feats = [emb(batch_x.to(device)).cpu().numpy()\n",
        "#                  for batch_x, _, _ in loader]\n",
        "#     data[name] = (np.concatenate(feats), split.get_metadata()['target'].values)\n",
        "\n",
        "\n",
        "# test_y_pred = clf_pipe.predict(data['test'][0])\n",
        "# Save to txt\n",
        "\n",
        "# test_bal_acc = balanced_accuracy_score(data['test'][1], test_y_pred)\n",
        "# print(f'Test bal acc: {test_bal_acc:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jOpA6U40KV"
      },
      "source": [
        "# Loading and predicting on the Unlabelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLMFtOy67gcA"
      },
      "source": [
        "testB = get_testB()\n",
        "split = RPD([ds for ds in testB.datasets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCkiHh2M45pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a9cfa3-63f3-4791-9ea0-f50520ac8509"
      },
      "source": [
        "# Loading BD data trainB and valB from dict\n",
        "# I need to reload only if I want to either train the Contrastive model, CNN or\n",
        "# if I want to create a dict will all BD data for better save. - Too much RAM \n",
        "\n",
        "save_path = \"/content/drive/MyDrive/mne_data/NeuroIPS_Hack_Sleep/\" \n",
        "# Load BrainDecode_data for trainB and valB\n",
        "bd_dat_file = \"BraindecodeData_Dict2\"\n",
        "BrainDecode_data = {}\n",
        "s = t()\n",
        "BrainDecode_data = load_obj(save_path,bd_dat_file)\n",
        "e = t()\n",
        "print(f\"Loading BD data {e-s}\")\n",
        "\n",
        "print(BrainDecode_data)\n",
        "\n",
        "trainB = BrainDecode_data[\"train\"]\n",
        "# # valB = BrainDecode_data[\"valid\"]\n",
        "# del BrainDecode_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BD data 107.36659359931946\n",
            "{'train': <braindecode.datasets.base.BaseConcatDataset object at 0x7f25fcd7a290>, 'valid': <braindecode.datasets.base.BaseConcatDataset object at 0x7f2477790550>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EnCYEu4LXxk"
      },
      "source": [
        "del BrainDecode_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsAigu6rLlxN"
      },
      "source": [
        "splitted['train'] = RPD([ds for ds in trainB.datasets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCO4pU02iQAt"
      },
      "source": [
        "# load embedder\n",
        "# Load the CNN\n",
        "# rp_ssc_checkpoints3 (2k, 1024, inc LR)\n",
        "# rp_ssc_checkpoints2 (2k, 1024)\n",
        "# rp_ssc_checkpoints2k_256 (2k, 256)\n",
        "# rp_ssc_checkpoints (250, 256)\n",
        "\n",
        "# Need the trained embedder not the classifier with the contrastive model\n",
        "SSLnet_path = save_path+\"rp_ssc_checkpoints3/\"\n",
        "clf = load_obj(SSLnet_path,\"final_model\")\n",
        "emb_c = clf.module.emb\n",
        "# del clf\n",
        "\n",
        "# load the other train and val data passed through embedder\n",
        "# SSL_classifier_path = save_path+\"RPClassifier/\" \n",
        "# name = \"Data_Dict\"\n",
        "# data = load_obj(SSL_classifier_path,name)\n",
        "\n",
        "#pass through embedder\n",
        "# For unlabelled a simple dataset should be equivalent since single win\n",
        "\n",
        "split.return_pair = False  # Return single windows\n",
        "batch_size = 1024\n",
        "num_workers = 0\n",
        "loader = DataLoader(split, batch_size=batch_size, num_workers=num_workers)\n",
        "with torch.no_grad():\n",
        "    feats = [emb_c(batch_x.to(device)).cpu().numpy()\n",
        "              for batch_x, _, _ in loader]\n",
        "# data['test'] = (np.concatenate(feats), split.get_metadata()['target'].values)\n",
        "emb_test_dat = (np.concatenate(feats), split.get_metadata()['target'].values)\n",
        "# full embedded dict\n",
        "# save_path = \"/content/drive/MyDrive/mne_data/RPClassifier/\" \n",
        "# with open(SSL_classifier_path+'Data_Dict_withTest.pkl', 'wb') as f:\n",
        "#     pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
        "# data_save(data,'RPClassifier/Data_Dict_withTest')\n",
        "\n",
        "# emb_test_dat = data['test']\n",
        "# del data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_HiPq7MjTcA",
        "outputId": "e1a1dd7f-e84b-43da-fd58-dfc9f0b03404"
      },
      "source": [
        "# max_iter = 1500\n",
        "# solver = \"newton-cg\"\n",
        "# log_reg = LogisticRegression(\n",
        "#     penalty='l2', C=1.0, class_weight='balanced', solver=solver,\n",
        "#     multi_class='multinomial', random_state=random_state,verbose=1,\n",
        "#     n_jobs=-1,max_iter=max_iter)\n",
        "# clf_pipe = make_pipeline(StandardScaler(), log_reg)\n",
        "\n",
        "# load clf_pipe\n",
        "SSL_classifier_path = save_path+\"RPClassifier/\" \n",
        "clf_pipe = load_obj(SSL_classifier_path,\"LogReg_newton-cg_1500\")\n",
        "\n",
        "# X_test = emb_c()\n",
        "# give as input to classifier.predict\n",
        "y_pred = clf_pipe.predict(emb_test_dat[0])\n",
        "print(\"Checking if all classes have been predicted\")\n",
        "print(np.unique(y_pred))\n",
        "save_fname = \"LogReg_newton-cg_1500\"\n",
        "np.savetxt(\"/content/drive/MyDrive/mne_data/predict/\"+save_fname+\".txt\",y_pred,delimiter=',',fmt=\"%d\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking if all classes have been predicted\n",
            "[0 1 2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iknfDglV6MeV"
      },
      "source": [
        "Other loading and ways of processing. Replaced by more simpler methods since these data need not be loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy3mhgnk5OKg"
      },
      "source": [
        "# BrainDecode_data[\"test\"] = get_testB()\n",
        "\n",
        "# Last time I had to interrupt and stop the saving because the RAM consumption was \n",
        "# bordering overflow on the High-RAM itself\n",
        "\n",
        "# data_save(BrainDecode_data,'BraindecodeData_Dict_withTest') \n",
        "\n",
        "# split = RPD([ds for ds in BrainDecode_data[\"test\"].datasets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy0a0RWrla0h"
      },
      "source": [
        "# get splitted by running train and val till RPD creation\n",
        "\n",
        "# Create RP Dataset\n",
        "# Only RP sampler requires subject split, dataset alone doesn't\n",
        "# splitted = dict()\n",
        "# splitted['train'] = RPD([ds for ds in BrainDecode_data[\"train\"].datasets])\n",
        "# splitted['valid'] = RPD([ds for ds in BrainDecode_data[\"valid\"].datasets])\n",
        "# splitted['test'] = RPD([ds for ds in BrainDecode_data[\"test\"].datasets])\n",
        "\n",
        "\n",
        "# Save splitted as a dict\n",
        "# save_path = \"/content/drive/MyDrive/mne_data/\" \n",
        "# with open(save_path+'RPDData_Dict.pkl', 'wb') as f:\n",
        "#     pickle.dump(splitted, f, pickle.HIGHEST_PROTOCOL)\n",
        "# del BrainDecode_data\n",
        "# data_save(splitted,'RPDData_Dict')\n",
        "# split = splitted['test']\n",
        "# del splitted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFOClDKysD2i"
      },
      "source": [
        "# clf train on 2nd group data with RP sampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ED9gY51rwvA"
      },
      "source": [
        "Training the SSL on the group 1 data has pretty poor performance at 47% on the unlabelled phase 1 leaderboard data - expected I guess considering that validation on the target dataset was pretty poor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPrLaZqIxp1Z"
      },
      "source": [
        "One more step for betterment of this - push more into functions so that local var.s are nicely destroyed automatically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igjaMArhV5YH"
      },
      "source": [
        "Total time for all data loading = 4+1.5+7+1.5 = ~15min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPo567Jm9myQ"
      },
      "source": [
        "# Load the model and do TL on the valB or target data from Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rABn8f9r0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6be37e-0f67-4262-ec3f-8cd6ede07f1a"
      },
      "source": [
        "# load embedder\n",
        "# Load the CNN\n",
        "# rp_ssc_checkpoints3 (2k, 1024, inc LR)\n",
        "# rp_ssc_checkpoints2 (2k, 1024)\n",
        "# rp_ssc_checkpoints2k_256 (2k, 256)\n",
        "# rp_ssc_checkpoints (250, 256)\n",
        "\n",
        "# Need the trained embedder not the classifier with the contrastive model\n",
        "save_path = \"/content/drive/MyDrive/mne_data/NeuroIPS_Hack_Sleep\"\n",
        "SSLnet_path = save_path+\"/rp_ssc_checkpoints3/\"\n",
        "\n",
        "clf = load_obj(SSLnet_path,\"final_model\")\n",
        "# emb_c = clf.module.emb\n",
        "# del clf\n",
        "\n",
        "# Need to modify the classifier for further training on the target valB\n",
        "# data without any validation dataset\n",
        "\n",
        "print(clf.get_params())\n",
        "# Activate warm_start or can also use partial_fit, but better warm_start\n",
        "# set train_split = None\n",
        "# changing the iterator_train_sampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cropped': False, 'module': ContrastiveNet(\n",
            "  (emb): SleepStagerChambon2018(\n",
            "    (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "    (feature_extractor): Sequential(\n",
            "      (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "      (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Dropout(p=0, inplace=False)\n",
            "      (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (clf): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            "), 'criterion': <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01, 'max_epochs': 150, 'batch_size': 1024, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': functools.partial(<function _make_split at 0x7f266ec6be60>, valid_ds=<__main__.RPD object at 0x7f262b3dd750>), 'callbacks': [('train_acc', <skorch.callbacks.scoring.EpochScoring object at 0x7f25c7ae0750>), ('valid_acc', <skorch.callbacks.scoring.EpochScoring object at 0x7f25c7ae0bd0>), ('checkpoint', <skorch.callbacks.training.Checkpoint object at 0x7f25c7ae0c90>), ('wandb', <skorch.callbacks.logging.WandbLogger object at 0x7f25c7a5e110>)], 'predict_nonlinearity': 'auto', 'warm_start': False, 'verbose': 1, 'device': 'cuda', 'iterator_train__shuffle': False, 'iterator_train__sampler': <braindecode.samplers.ssl.RelativePositioningSampler object at 0x7f25c7a5e450>, 'iterator_valid__sampler': <braindecode.samplers.ssl.RelativePositioningSampler object at 0x7f25c7a69890>, 'iterator_train__num_workers': 0, 'iterator_valid__num_workers': 0, 'classes': None, 'optimizer__lr': 0.05, 'callbacks__epoch_timer': <skorch.callbacks.logging.EpochTimer object at 0x7f262b327450>, 'callbacks__train_loss': <skorch.callbacks.scoring.BatchScoring object at 0x7f2630bdfed0>, 'callbacks__train_loss__scoring': <function train_loss_score at 0x7f266ec65dd0>, 'callbacks__train_loss__lower_is_better': True, 'callbacks__train_loss__on_train': True, 'callbacks__train_loss__name': 'train_loss', 'callbacks__train_loss__target_extractor': <function noop at 0x7f266ec65f80>, 'callbacks__train_loss__use_caching': True, 'callbacks__valid_loss': <skorch.callbacks.scoring.BatchScoring object at 0x7f2630bdfa50>, 'callbacks__valid_loss__scoring': <function valid_loss_score at 0x7f266ec6bdd0>, 'callbacks__valid_loss__lower_is_better': True, 'callbacks__valid_loss__on_train': False, 'callbacks__valid_loss__name': 'valid_loss', 'callbacks__valid_loss__target_extractor': <function noop at 0x7f266ec65f80>, 'callbacks__valid_loss__use_caching': True, 'callbacks__train_acc': <skorch.callbacks.scoring.EpochScoring object at 0x7f25c7ae0750>, 'callbacks__train_acc__scoring': 'accuracy', 'callbacks__train_acc__lower_is_better': False, 'callbacks__train_acc__on_train': True, 'callbacks__train_acc__name': 'train_acc', 'callbacks__train_acc__target_extractor': <function to_numpy at 0x7f26c7e38b90>, 'callbacks__train_acc__use_caching': True, 'callbacks__valid_acc': <skorch.callbacks.scoring.EpochScoring object at 0x7f25c7ae0bd0>, 'callbacks__valid_acc__scoring': 'accuracy', 'callbacks__valid_acc__lower_is_better': False, 'callbacks__valid_acc__on_train': False, 'callbacks__valid_acc__name': 'valid_acc', 'callbacks__valid_acc__target_extractor': <function to_numpy at 0x7f26c7e38b90>, 'callbacks__valid_acc__use_caching': True, 'callbacks__checkpoint': <skorch.callbacks.training.Checkpoint object at 0x7f25c7ae0c90>, 'callbacks__checkpoint__monitor': 'valid_acc_best', 'callbacks__checkpoint__f_params': None, 'callbacks__checkpoint__f_optimizer': None, 'callbacks__checkpoint__f_criterion': None, 'callbacks__checkpoint__f_history': 'history.json', 'callbacks__checkpoint__f_pickle': 'model_{last_epoch[epoch]}.pkl', 'callbacks__checkpoint__fn_prefix': '', 'callbacks__checkpoint__dirname': '/content/drive/MyDrive/mne_data/rp_ssc_checkpoints3', 'callbacks__checkpoint__event_name': 'event_cp', 'callbacks__checkpoint__sink': <function noop at 0x7f266ec65f80>, 'callbacks__wandb': <skorch.callbacks.logging.WandbLogger object at 0x7f25c7a5e110>, 'callbacks__wandb__wandb_run': <wandb.sdk.wandb_run.Run object at 0x7f25c7a5e1d0>, 'callbacks__wandb__save_model': True, 'callbacks__wandb__keys_ignored': None, 'callbacks__print_log': <skorch.callbacks.logging.PrintLog object at 0x7f262b1611d0>, 'callbacks__print_log__keys_ignored': None, 'callbacks__print_log__sink': <built-in function print>, 'callbacks__print_log__tablefmt': 'simple', 'callbacks__print_log__floatfmt': '.4f', 'callbacks__print_log__stralign': 'right'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZovrnrp1pkQ",
        "outputId": "7fd612f2-edfc-4233-b60e-6dbf6061d2b0"
      },
      "source": [
        "trained_model = clf.module\n",
        "print(trained_model)\n",
        "print(type(trained_model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContrastiveNet(\n",
            "  (emb): SleepStagerChambon2018(\n",
            "    (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "    (feature_extractor): Sequential(\n",
            "      (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "      (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Dropout(p=0, inplace=False)\n",
            "      (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (clf): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "<class '__main__.ContrastiveNet'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5KTOQ-f3EkN"
      },
      "source": [
        "# Currently prediciton on the valB is pretty much chance level\n",
        "# That's not expected. But let's go on"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "59mkm1aq4aW3",
        "outputId": "f44a8780-2b57-4f2d-bfda-3b39df48a60c"
      },
      "source": [
        "# start wandb\n",
        "# wandb\n",
        "# should I set reinit = true?\n",
        "wandb_run = wandb.init(name = \"RP-SSL SSC2018 TL1 train\", project='RP-fulltrain', entity='sleep_hacking')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiv12345\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">RP-SSL SSC2018 TL1 train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1v4l83h9\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1v4l83h9</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210929_185226-1v4l83h9</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bcdIqHC2jCY",
        "outputId": "9a4ef1cd-4ee6-4e3f-ca41-0e3cfb8cfd42"
      },
      "source": [
        "# I can define a new BD classifier simply and just give this module as input and it will work fine\n",
        "# or I can modify the parameters in this model itself\n",
        "\n",
        "# Train the network\n",
        "lr = 5e-2 # 5e-4\n",
        "batch_size = 1024 # increase this next time\n",
        "n_epochs = 150\n",
        "num_workers = 0 # if n_jobs <= 1 else n_jobs\n",
        "\n",
        "# Callback WandbLogger logs the \"best trained model\", etc. after every epoch\n",
        "# Not sure of definition of best trained\n",
        "\n",
        "# TODO - \n",
        "# Add early stopping with 10 on valid_bacc I guess - \n",
        "# This fails if big oscillations happens, but well the lr is low\n",
        "\n",
        "# should make this function of parameters for easiness\n",
        "save_path = \"/content/drive/MyDrive/mne_data/NeuroIPS_Hack_Sleep/rp_ssc_TL1_checkpoints1\" \n",
        "\n",
        "# Log hyperparameters\n",
        "wandb_run.config.update({\"Embedder_size\":emb_size, \"learning rate\": lr, \n",
        "                         \"batch size\": batch_size, \"n_conv_chs_SSC\": n_conv_chs,\n",
        "                         \"tau_pos\":tau_pos, \"tau_neg\":tau_neg, \"n_examples_RPsampler\":n_examples,\n",
        "                         \"n_examples_val\":n_examples_valid,\n",
        "                         \"save_path\":save_path})\n",
        "\n",
        "# org paper used a weight decay of 1e-3 on all trainable params\n",
        "cp = Checkpoint(monitor = 'val_acc_best',\n",
        "                f_params = \"params_{last_epoch[epoch]}.pt\", \n",
        "                f_optimizer = \"optimizer_{last_epoch[epoch]}.pt\", \n",
        "                f_criterion = \"criterion_{last_epoch[epoch]}.pt\",\n",
        "                # f_pickle = \"model_{last_epoch[epoch]}.pkl\",\n",
        "                dirname = save_path)\n",
        "train_end_cp = TrainEndCheckpoint(\n",
        "                f_params = \"params_{last_epoch[epoch]}.pt\", \n",
        "                f_optimizer = \"optimizer_{last_epoch[epoch]}.pt\", \n",
        "                f_criterion = \"criterion_{last_epoch[epoch]}.pt\",\n",
        "                dirname=save_path)\n",
        "# giving this name 'val_acc' since I want this logged in val acc in Wandb\n",
        "train_acc = EpochScoring(\n",
        "    scoring='accuracy', on_train=True, name='val_acc', \n",
        "    lower_is_better=False)\n",
        "# valid_acc = EpochScoring(\n",
        "#     scoring='accuracy', on_train=False, name='valid_acc',\n",
        "#     lower_is_better=False)\n",
        "callbacks = [('val_acc', train_acc),\n",
        "            #  ('valid_acc', valid_acc),\n",
        "             (\"train_end_cp\",train_end_cp),\n",
        "             (\"checkpoint\",cp),\n",
        "             (\"wandb\",WandbLogger(wandb_run, save_model=False))\n",
        "             ]\n",
        "\n",
        "clf2 = EEGClassifier(\n",
        "    trained_model,\n",
        "    criterion=torch.nn.BCEWithLogitsLoss,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    max_epochs=n_epochs,\n",
        "    iterator_train__shuffle=False,\n",
        "    iterator_train__sampler=valid_sampler,\n",
        "    # iterator_valid__sampler=valid_sampler,\n",
        "    iterator_train__num_workers=num_workers,\n",
        "    # iterator_valid__num_workers=num_workers,\n",
        "    train_split = None,\n",
        "    # train_split=predefined_split(splitted['valid']),\n",
        "    optimizer__lr=lr,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        "    device=device,\n",
        "    # warm_start = True\n",
        "    # **arg_dict\n",
        ")\n",
        "\n",
        "print(clf2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'braindecode.classifier.EEGClassifier'>[uninitialized](\n",
            "  module=ContrastiveNet(\n",
            "    (emb): SleepStagerChambon2018(\n",
            "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
            "      (feature_extractor): Sequential(\n",
            "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
            "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (6): ReLU()\n",
            "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (fc): Sequential(\n",
            "        (0): Dropout(p=0, inplace=False)\n",
            "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (clf): Sequential(\n",
            "      (0): Dropout(p=0.5, inplace=False)\n",
            "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
            "    )\n",
            "  ),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtlMUVti6HEY",
        "outputId": "196a5e88-9395-46ea-b9a4-e9c89c07040e"
      },
      "source": [
        "# del clf\n",
        "mne.set_log_level(True)\n",
        "clf2.fit(splitted['valid'], y=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    val_acc    cp     dur\n",
            "-------  ------------  ---------  ----  ------\n",
            "      1        \u001b[36m1.9929\u001b[0m     \u001b[32m0.5124\u001b[0m     +  2.8557\n",
            "      2        \u001b[36m1.0810\u001b[0m     0.5112        2.8396\n",
            "      3        \u001b[36m0.8254\u001b[0m     \u001b[32m0.5144\u001b[0m     +  2.8365\n",
            "      4        \u001b[36m0.7781\u001b[0m     \u001b[32m0.5198\u001b[0m     +  2.8430\n",
            "      5        \u001b[36m0.7431\u001b[0m     \u001b[32m0.5309\u001b[0m     +  2.8216\n",
            "      6        \u001b[36m0.7257\u001b[0m     \u001b[32m0.5397\u001b[0m     +  2.8428\n",
            "      7        \u001b[36m0.7090\u001b[0m     \u001b[32m0.5504\u001b[0m     +  2.8109\n",
            "      8        \u001b[36m0.7041\u001b[0m     \u001b[32m0.5507\u001b[0m     +  2.9017\n",
            "      9        \u001b[36m0.6913\u001b[0m     \u001b[32m0.5653\u001b[0m     +  2.8378\n",
            "     10        \u001b[36m0.6825\u001b[0m     \u001b[32m0.5774\u001b[0m     +  2.8198\n",
            "     11        \u001b[36m0.6710\u001b[0m     \u001b[32m0.5889\u001b[0m     +  2.8064\n",
            "     12        \u001b[36m0.6653\u001b[0m     \u001b[32m0.5996\u001b[0m     +  2.8146\n",
            "     13        \u001b[36m0.6630\u001b[0m     0.5961        2.7997\n",
            "     14        \u001b[36m0.6562\u001b[0m     \u001b[32m0.6008\u001b[0m     +  2.8133\n",
            "     15        \u001b[36m0.6522\u001b[0m     \u001b[32m0.6088\u001b[0m     +  2.8190\n",
            "     16        \u001b[36m0.6489\u001b[0m     \u001b[32m0.6126\u001b[0m     +  2.8174\n",
            "     17        \u001b[36m0.6458\u001b[0m     \u001b[32m0.6178\u001b[0m     +  2.8252\n",
            "     18        \u001b[36m0.6412\u001b[0m     \u001b[32m0.6222\u001b[0m     +  2.8089\n",
            "     19        \u001b[36m0.6369\u001b[0m     0.6191        2.8429\n",
            "     20        \u001b[36m0.6332\u001b[0m     \u001b[32m0.6309\u001b[0m     +  2.8365\n",
            "     21        0.6342     0.6288        2.8475\n",
            "     22        \u001b[36m0.6302\u001b[0m     \u001b[32m0.6356\u001b[0m     +  2.8223\n",
            "     23        \u001b[36m0.6245\u001b[0m     \u001b[32m0.6380\u001b[0m     +  2.8305\n",
            "     24        \u001b[36m0.6198\u001b[0m     \u001b[32m0.6482\u001b[0m     +  2.8577\n",
            "     25        \u001b[36m0.6173\u001b[0m     0.6443        2.8255\n",
            "     26        0.6179     0.6442        2.8242\n",
            "     27        0.6192     \u001b[32m0.6483\u001b[0m     +  2.8150\n",
            "     28        0.6182     0.6458        2.7982\n",
            "     29        \u001b[36m0.6128\u001b[0m     \u001b[32m0.6526\u001b[0m     +  2.8001\n",
            "     30        0.6144     \u001b[32m0.6551\u001b[0m     +  2.8135\n",
            "     31        \u001b[36m0.6077\u001b[0m     \u001b[32m0.6593\u001b[0m     +  2.8423\n",
            "     32        \u001b[36m0.6036\u001b[0m     \u001b[32m0.6633\u001b[0m     +  2.8174\n",
            "     33        \u001b[36m0.6014\u001b[0m     \u001b[32m0.6667\u001b[0m     +  2.8413\n",
            "     34        \u001b[36m0.5993\u001b[0m     0.6664        2.8618\n",
            "     35        \u001b[36m0.5969\u001b[0m     \u001b[32m0.6683\u001b[0m     +  2.8641\n",
            "     36        0.6023     0.6637        6.4264\n",
            "     37        \u001b[36m0.5952\u001b[0m     \u001b[32m0.6739\u001b[0m     +  2.7790\n",
            "     38        \u001b[36m0.5951\u001b[0m     0.6722        2.7755\n",
            "     39        \u001b[36m0.5905\u001b[0m     \u001b[32m0.6760\u001b[0m     +  2.7895\n",
            "     40        0.5908     0.6757        2.8015\n",
            "     41        \u001b[36m0.5884\u001b[0m     \u001b[32m0.6802\u001b[0m     +  2.8142\n",
            "     42        \u001b[36m0.5873\u001b[0m     0.6786        2.8022\n",
            "     43        0.5955     0.6727        2.7801\n",
            "     44        \u001b[36m0.5863\u001b[0m     \u001b[32m0.6809\u001b[0m     +  2.7749\n",
            "     45        \u001b[36m0.5826\u001b[0m     \u001b[32m0.6868\u001b[0m     +  2.7704\n",
            "     46        \u001b[36m0.5755\u001b[0m     \u001b[32m0.6913\u001b[0m     +  2.8184\n",
            "     47        0.5761     \u001b[32m0.6936\u001b[0m     +  2.7873\n",
            "     48        \u001b[36m0.5722\u001b[0m     \u001b[32m0.6995\u001b[0m     +  2.7840\n",
            "     49        \u001b[36m0.5686\u001b[0m     0.6982        2.8063\n",
            "     50        \u001b[36m0.5605\u001b[0m     \u001b[32m0.7076\u001b[0m     +  2.8079\n",
            "     51        0.5621     0.7027        2.7967\n",
            "     52        0.5621     0.7031        2.7858\n",
            "     53        \u001b[36m0.5573\u001b[0m     \u001b[32m0.7107\u001b[0m     +  2.8028\n",
            "     54        \u001b[36m0.5564\u001b[0m     0.7099        2.7928\n",
            "     55        0.5604     0.7082        2.7777\n",
            "     56        0.5725     0.6943        2.7826\n",
            "     57        0.5793     0.6910        2.7726\n",
            "     58        0.5649     0.7012        2.8089\n",
            "     59        \u001b[36m0.5544\u001b[0m     \u001b[32m0.7137\u001b[0m     +  2.7904\n",
            "     60        \u001b[36m0.5478\u001b[0m     \u001b[32m0.7202\u001b[0m     +  2.7773\n",
            "     61        0.5517     0.7142        2.7883\n",
            "     62        0.5486     0.7184        2.7912\n",
            "     63        \u001b[36m0.5465\u001b[0m     0.7170        2.7845\n",
            "     64        0.5478     0.7173        2.7927\n",
            "     65        0.5472     0.7198        2.8084\n",
            "     66        \u001b[36m0.5368\u001b[0m     \u001b[32m0.7246\u001b[0m     +  2.8013\n",
            "     67        \u001b[36m0.5298\u001b[0m     \u001b[32m0.7299\u001b[0m     +  2.7925\n",
            "     68        0.5322     0.7289        2.7969\n",
            "     69        0.5333     0.7281        2.7773\n",
            "     70        0.5304     0.7299        2.7913\n",
            "     71        0.5433     0.7209        2.7734\n",
            "     72        0.5672     0.7077        2.7824\n",
            "     73        0.5567     0.7115        2.7916\n",
            "     74        0.5340     \u001b[32m0.7318\u001b[0m     +  2.8100\n",
            "     75        \u001b[36m0.5183\u001b[0m     \u001b[32m0.7403\u001b[0m     +  2.8070\n",
            "     76        0.5232     0.7362        2.7835\n",
            "     77        0.5195     0.7370        2.8062\n",
            "     78        0.5221     \u001b[32m0.7408\u001b[0m     +  2.7877\n",
            "     79        0.5220     \u001b[32m0.7412\u001b[0m     +  2.7890\n",
            "     80        \u001b[36m0.5111\u001b[0m     \u001b[32m0.7464\u001b[0m     +  2.7931\n",
            "     81        0.5157     0.7431        2.7990\n",
            "     82        0.5144     0.7452        2.7753\n",
            "     83        0.5197     0.7412        2.8327\n",
            "     84        0.5147     0.7422        2.7935\n",
            "     85        0.5161     0.7416        2.7862\n",
            "     86        0.5113     \u001b[32m0.7486\u001b[0m     +  2.7783\n",
            "     87        0.5154     0.7442        2.7904\n",
            "     88        \u001b[36m0.4979\u001b[0m     \u001b[32m0.7553\u001b[0m     +  2.7999\n",
            "     89        0.5030     0.7526        2.8033\n",
            "     90        0.5006     0.7507        2.8024\n",
            "     91        \u001b[36m0.4944\u001b[0m     \u001b[32m0.7585\u001b[0m     +  2.8041\n",
            "     92        0.4945     0.7572        2.8226\n",
            "     93        0.5025     0.7498        2.8225\n",
            "     94        0.5010     0.7562        2.8078\n",
            "     95        0.5131     0.7485        2.7966\n",
            "     96        0.5153     0.7397        2.7886\n",
            "     97        0.5074     0.7534        2.8041\n",
            "     98        0.5134     0.7458        2.8013\n",
            "     99        0.5104     0.7508        2.8231\n",
            "    100        0.4946     \u001b[32m0.7596\u001b[0m     +  2.8426\n",
            "    101        0.5051     0.7516        2.8030\n",
            "    102        \u001b[36m0.4930\u001b[0m     0.7585        2.8068\n",
            "    103        0.5072     0.7509        2.7898\n",
            "    104        0.5129     0.7466        2.8138\n",
            "    105        0.4997     0.7547        2.8063\n",
            "    106        0.5010     0.7544        2.8186\n",
            "    107        0.4988     0.7497        2.8233\n",
            "    108        \u001b[36m0.4926\u001b[0m     0.7571        2.8431\n",
            "    109        \u001b[36m0.4808\u001b[0m     \u001b[32m0.7669\u001b[0m     +  2.8252\n",
            "    110        \u001b[36m0.4787\u001b[0m     0.7644        2.8355\n",
            "    111        \u001b[36m0.4715\u001b[0m     \u001b[32m0.7744\u001b[0m     +  2.8043\n",
            "    112        0.4763     0.7698        2.8305\n",
            "    113        0.4772     0.7672        2.8313\n",
            "    114        0.4787     0.7652        2.8215\n",
            "    115        0.4800     0.7639        2.8535\n",
            "    116        0.4910     0.7584        2.8352\n",
            "    117        0.5063     0.7532        2.8419\n",
            "    118        0.5056     0.7532        2.8367\n",
            "    119        0.4929     0.7584        2.8363\n",
            "    120        0.4775     0.7691        2.8143\n",
            "    121        0.4724     0.7731        2.8318\n",
            "    122        0.4738     \u001b[32m0.7753\u001b[0m     +  2.8391\n",
            "    123        0.4743     0.7711        2.8466\n",
            "    124        \u001b[36m0.4680\u001b[0m     0.7747        2.8420\n",
            "    125        \u001b[36m0.4524\u001b[0m     \u001b[32m0.7856\u001b[0m     +  2.8176\n",
            "    126        0.4630     0.7828        2.8221\n",
            "    127        0.4649     0.7773        2.7936\n",
            "    128        0.4746     0.7682        2.7949\n",
            "    129        0.4810     0.7636        2.7947\n",
            "    130        0.4809     0.7646        2.7852\n",
            "    131        0.4854     0.7611        2.7868\n",
            "    132        0.4899     0.7618        2.7903\n",
            "    133        0.4612     0.7779        2.8220\n",
            "    134        0.4541     0.7826        2.8094\n",
            "    135        \u001b[36m0.4377\u001b[0m     \u001b[32m0.7962\u001b[0m     +  2.8148\n",
            "    136        \u001b[36m0.4279\u001b[0m     \u001b[32m0.8027\u001b[0m     +  2.8030\n",
            "    137        \u001b[36m0.4278\u001b[0m     0.7986        2.8097\n",
            "    138        0.4303     0.7982        2.8118\n",
            "    139        \u001b[36m0.4207\u001b[0m     \u001b[32m0.8043\u001b[0m     +  2.8310\n",
            "    140        0.4215     \u001b[32m0.8058\u001b[0m     +  2.8322\n",
            "    141        \u001b[36m0.4199\u001b[0m     0.8050        2.8496\n",
            "    142        0.4313     0.7967        2.8037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:38.734775, resuming normal operation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    143        0.4225     0.8038        2.8019\n",
            "    144        0.4237     0.8043        2.8088\n",
            "    145        0.4202     0.8016        2.8036\n",
            "    146        \u001b[36m0.4125\u001b[0m     \u001b[32m0.8111\u001b[0m     +  2.8197\n",
            "    147        0.4150     0.8078        2.8452\n",
            "    148        \u001b[36m0.4105\u001b[0m     0.8093        2.8154\n",
            "    149        \u001b[36m0.4091\u001b[0m     0.8096        2.8376\n",
            "    150        0.4099     0.8106        2.8442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=ContrastiveNet(\n",
              "    (emb): SleepStagerChambon2018(\n",
              "      (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))\n",
              "      (feature_extractor): Sequential(\n",
              "        (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (6): ReLU()\n",
              "        (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (fc): Sequential(\n",
              "        (0): Dropout(p=0, inplace=False)\n",
              "        (1): Linear(in_features=544, out_features=100, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (clf): Sequential(\n",
              "      (0): Dropout(p=0.5, inplace=False)\n",
              "      (1): Linear(in_features=100, out_features=1, bias=True)\n",
              "    )\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5z9ftG9-ac-",
        "outputId": "c676e9dc-00af-491c-95cf-8c088b57f933"
      },
      "source": [
        "# Confusion matrix of ValB\n",
        "# Use the val itself to see the matrix\n",
        "clf2.iterator_valid__sampler = valid_sampler\n",
        "y_pred = clf2.forward(splitted['valid'], training=False) > 0\n",
        "\n",
        "y_true = [y for _, _, y in valid_sampler]\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5136  785]\n",
            " [1572 4507]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.87      0.81      5921\n",
            "         1.0       0.85      0.74      0.79      6079\n",
            "\n",
            "    accuracy                           0.80     12000\n",
            "   macro avg       0.81      0.80      0.80     12000\n",
            "weighted avg       0.81      0.80      0.80     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462,
          "referenced_widgets": [
            "c38469a2d1f74d3387f402a361903523",
            "74295ebc0fcd413b9a75914fbc0d1752",
            "c38ab60816ad474689b20ce12f8df3e3",
            "dda9972ba5a94292a5cc08ca99b85bb9",
            "eebede281c424c5da51b65709f652d68",
            "9731bb1d6ef24e7c8508636313972df9",
            "8bd49ea4c16246f6bbfc0f9e2253126b",
            "888c08f31b4147e7951105d297fe6315"
          ]
        },
        "id": "LtzARkZ4B2q3",
        "outputId": "f0cd8dc3-2f60-4bd4-c34c-01f9548a8a38"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1857<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c38469a2d1f74d3387f402a361903523",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210929_185226-1v4l83h9/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210929_185226-1v4l83h9/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>dur</td><td>2.84418</td></tr><tr><td>train_loss</td><td>0.40989</td></tr><tr><td>val_acc</td><td>0.81058</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>dur</td><td>▇▆▄▄▅▆▅▄▆█▂▄▁▄▃▁▂▄▂▃▄▂▆▂▄▃▅▂▅▄▆▆▆▅▃▅▄▇▃▆</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">RP-SSL SSC2018 TL1 train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1v4l83h9\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/1v4l83h9</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fYAyxpxABo4"
      },
      "source": [
        "Before overfitting predict on the leaderboard and see the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec3oQlCVAaW-"
      },
      "source": [
        "# Get the features from the val and test now and see the classifier performance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzYI-vDE6dnf"
      },
      "source": [
        "print(splitted['valid'].__dict__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "batG4A4I6oK1",
        "outputId": "605fb625-e1b1-4236-e107-bc5c4536a647"
      },
      "source": [
        "print(len(splitted['valid'].datasets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLWIgqy7YQW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkLPj9xaA9Vc"
      },
      "source": [
        "# Need the trained embedder not the classifier with the contrastive model\n",
        "emb_c = clf2.module.emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLG-t-7BA9Vf"
      },
      "source": [
        "# Extract features with the trained embedder\n",
        "data = dict()\n",
        "# splitted has the RPDataset \n",
        "# For unlabelled a simple dataset should be equivalent since single win\n",
        "for name, split in splitted.items():\n",
        "    # run the till the RP sampler above\n",
        "    split.return_pair = False  # Return single windows\n",
        "    loader = DataLoader(split, batch_size=batch_size, num_workers=num_workers)\n",
        "    with torch.no_grad():\n",
        "        feats = [emb_c(batch_x.to(device)).cpu().numpy()\n",
        "                 for batch_x, _, _ in loader]\n",
        "    data[name] = (np.concatenate(feats), split.get_metadata()['target'].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd7LnUs4Bwvg",
        "outputId": "b10d2ef0-880e-4096-bc0b-991110e2e26e"
      },
      "source": [
        "print(data.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['valid', 'test', 'train'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "6fOUmwnFCXJR",
        "outputId": "886951ed-1462-48a3-ea78-c11db15de197"
      },
      "source": [
        "# wandb for the classifier - same project diff name should be fine\n",
        "wandb_run = wandb.init(name = \"Classifier train\", project='RP-fulltrain', entity='sleep_hacking')\n",
        "max_iter = 1500\n",
        "solver = \"newton-cg\"\n",
        "save_path = \"/content/drive/MyDrive/mne_data/NeuroIPS_Hack_Sleep/RPClassifier/\" \n",
        "clf_path = save_path+'TL1_1_LogReg_newton-cg_1500.pkl'\n",
        "wandb.config.update({'classifier type':'log_reg','solver':solver,\"max_iter\":max_iter,\"TL on Phase\":1,\"clf_path\":clf_path})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">Classifier train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/562w0u1s\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/562w0u1s</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210929_193824-562w0u1s</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e15MBFwECXJT"
      },
      "source": [
        "# max_iter = 1500\n",
        "# solver = \"newton-cg\"\n",
        "log_reg = LogisticRegression(\n",
        "    penalty='l2', C=1.0, class_weight='balanced', solver=solver,\n",
        "    multi_class='multinomial', random_state=random_state,verbose=1,\n",
        "    n_jobs=-1,max_iter=max_iter)\n",
        "clf_pipe = make_pipeline(StandardScaler(), log_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEprtdILCXJT",
        "outputId": "feb9de88-a80a-4d3f-f336-4fcaff07337e"
      },
      "source": [
        "s = t()\n",
        "clf_pipe.fit(*data['valid'])\n",
        "e = t()\n",
        "print(f\"Fit time {e-s}\")\n",
        "\n",
        "train_y_pred = clf_pipe.predict(data['valid'][0])\n",
        "train_bal_acc = balanced_accuracy_score(data['valid'][1], train_y_pred)\n",
        "print(f'Train bal acc: {train_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": train_bal_acc})\n",
        "\n",
        "print('Results on valid set(trained on valid set here):')\n",
        "print(confusion_matrix(data['valid'][1], train_y_pred))\n",
        "print(classification_report(data['valid'][1], train_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['valid'][1], train_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   14.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time 14.112605571746826\n",
            "Train bal acc: 0.4241\n",
            "Results on valid set(trained on valid set here):\n",
            "[[3711  750  169  255  384  741]\n",
            " [ 400  424  171  122  131  424]\n",
            " [ 573  677 1281  901  631  972]\n",
            " [  42   37  104  258  225   38]\n",
            " [  11    6   36   85  272    4]\n",
            " [ 299  288  176  113   95  636]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.62      0.67      6010\n",
            "           1       0.19      0.25      0.22      1672\n",
            "           2       0.66      0.25      0.37      5035\n",
            "           3       0.15      0.37      0.21       704\n",
            "           4       0.16      0.66      0.25       414\n",
            "           5       0.23      0.40      0.29      1607\n",
            "\n",
            "    accuracy                           0.43     15442\n",
            "   macro avg       0.35      0.42      0.34     15442\n",
            "weighted avg       0.56      0.43      0.45     15442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyIbk6_zCXJV"
      },
      "source": [
        "# Save the model, also log to wandb I guess\n",
        "with open(clf_path, 'wb') as f:\n",
        "    pickle.dump(clf_pipe, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376,
          "referenced_widgets": [
            "8e872f1bd30e4e8bb82402e00cab4563",
            "bb30808baa4a406da9265ddbda1889f6",
            "c867d8d9450c4a5fb0ff2b93a87b4994",
            "8bc1ce3c46dd4b0db7ef8134b1ec24e1",
            "93c22be09feb4057bf2c2b134bfc8072",
            "b3f100c06ad04078873a0327d1f1001b",
            "3e8b52b61eab4b3b9faf77b33602cf55",
            "9dc8b4ce1f584fa9b9f0fda2253530e8"
          ]
        },
        "id": "z_k2vf4XCXJV",
        "outputId": "9b4a0082-5ec5-4cdc-e427-8a4e8f3f5cf1"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2482<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e872f1bd30e4e8bb82402e00cab4563",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210929_193824-562w0u1s/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210929_193824-562w0u1s/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>0.42412</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">Classifier train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/562w0u1s\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/562w0u1s</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5fA4pNoghY8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpNZ98WmJogz"
      },
      "source": [
        "If the representation learnt on the second stage had been good, I could've tried things like training the clf on the first group and phase 1 val data combined and sought to improve overall clf performance, but IDK what to do in this case\n",
        "\n",
        "Maybe try loading the trainB anyways, try using this embedder on that, then try teaching this clf on that embedded rep? OR combine that embedded rep with the one from"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "BY4DQah3MWy9",
        "outputId": "dab786ec-a5a7-4b75-f299-c826184fc43e"
      },
      "source": [
        "# Train clf on only Train first\n",
        "# wandb for the classifier - same project diff name should be fine\n",
        "wandb_run = wandb.init(name = \"Classifier train\", project='RP-fulltrain', entity='sleep_hacking')\n",
        "max_iter = 1500\n",
        "solver = \"newton-cg\"\n",
        "save_path = \"/content/drive/MyDrive/mne_data/NeuroIPS_Hack_Sleep/RPClassifier/\" \n",
        "clf_path = save_path+'TL1_2_LogReg_newton-cg_1500.pkl'\n",
        "wandb.config.update({'classifier type':'log_reg','solver':solver,\"max_iter\":max_iter,\"TL on Phase\":1,\"clf_path\":clf_path})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">Classifier train</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3gpn2vdk\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3gpn2vdk</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210929_201838-3gpn2vdk</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSy8ZRM7M2rB"
      },
      "source": [
        "# max_iter = 1500\n",
        "# solver = \"newton-cg\"\n",
        "log_reg = LogisticRegression(\n",
        "    penalty='l2', C=1.0, class_weight='balanced', solver=solver,\n",
        "    multi_class='multinomial', random_state=random_state,verbose=1,\n",
        "    n_jobs=-1,max_iter=max_iter)\n",
        "clf_pipe = make_pipeline(StandardScaler(), log_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHxlhDonMpwB",
        "outputId": "98c74327-ec9a-446b-bd17-b99c4e1d9718"
      },
      "source": [
        "s = t()\n",
        "clf_pipe.fit(*data['train'])\n",
        "e = t()\n",
        "print(f\"Fit time {e-s}\")\n",
        "\n",
        "train_y_pred = clf_pipe.predict(data['train'][0])\n",
        "train_bal_acc = balanced_accuracy_score(data['train'][1], train_y_pred)\n",
        "print(f'Train bal acc: {train_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": train_bal_acc})\n",
        "\n",
        "print('Results on valid set(trained on valid set here):')\n",
        "print(confusion_matrix(data['train'][1], train_y_pred))\n",
        "print(classification_report(data['train'][1], train_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['train'][1], train_y_pred)\n",
        "###\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time 140.67068433761597\n",
            "Train bal acc: 0.4180\n",
            "Results on valid set(trained on valid set here):\n",
            "[[15366  4121   668   753   714  2421]\n",
            " [ 1421  2959   879   460   447  1775]\n",
            " [ 2641  6865  9602  5628  4392  6855]\n",
            " [  109   261   797  1643  1956   481]\n",
            " [   16    97   220   688  1872   164]\n",
            " [ 2222  3844  1895  1037   941  4335]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.67     24043\n",
            "           1       0.16      0.37      0.23      7941\n",
            "           2       0.68      0.27      0.38     35983\n",
            "           3       0.16      0.31      0.21      5247\n",
            "           4       0.18      0.61      0.28      3057\n",
            "           5       0.27      0.30      0.29     14274\n",
            "\n",
            "    accuracy                           0.40     90545\n",
            "   macro avg       0.36      0.42      0.34     90545\n",
            "weighted avg       0.53      0.40      0.42     90545\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RMwO2AaNYr3",
        "outputId": "c80c1bef-2eab-4d6b-aeab-4119e6e673bd"
      },
      "source": [
        "\n",
        "valid_y_pred = clf_pipe.predict(data['valid'][0])\n",
        "valid_bal_acc = balanced_accuracy_score(data['valid'][1], valid_y_pred)\n",
        "print(f'Train bal acc: {valid_bal_acc:0.4f}')\n",
        "wandb.log({\"Train bal Acc\": valid_bal_acc})\n",
        "\n",
        "print('Results on valid set(trained on valid set here):')\n",
        "print(confusion_matrix(data['valid'][1], valid_y_pred))\n",
        "print(classification_report(data['valid'][1], valid_y_pred))\n",
        "wandb.sklearn.plot_confusion_matrix(data['valid'][1], valid_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train bal acc: 0.3426\n",
            "Results on valid set(trained on valid set here):\n",
            "[[3121 1376  182  127  351  853]\n",
            " [ 388  510  190  101   92  391]\n",
            " [ 464  933 1411  623  535 1069]\n",
            " [  25   44  129  189  187  130]\n",
            " [   4    7   50  118  171   64]\n",
            " [ 356  479  210   65   64  433]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.52      0.60      6010\n",
            "           1       0.15      0.31      0.20      1672\n",
            "           2       0.65      0.28      0.39      5035\n",
            "           3       0.15      0.27      0.20       704\n",
            "           4       0.12      0.41      0.19       414\n",
            "           5       0.15      0.27      0.19      1607\n",
            "\n",
            "    accuracy                           0.38     15442\n",
            "   macro avg       0.32      0.34      0.30     15442\n",
            "weighted avg       0.53      0.38      0.42     15442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3rPh-dQH9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "91aac24d57c44263a762c551b1412e09",
            "58706cd4cc0b4b6595238461f145194f",
            "896abb471fa0480f8967f8aa8f585050",
            "afcf3abe5bbc44ba9ac2ccf0c6afc9f1",
            "4aecf725a07b4ec7b5bc36fdbda2ffbd",
            "7818a58c63274658bf29b8561634100a",
            "a309cd9858d34ba390ca61e5f13a7c01",
            "8498c6cb5a934ee2b74c7cc854e94822"
          ]
        },
        "outputId": "c137be50-3090-4d2b-ad92-e84ab247c440"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3067<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:03:25.123336, resuming normal operation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91aac24d57c44263a762c551b1412e09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210929_201838-3gpn2vdk/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210929_201838-3gpn2vdk/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>0.34259</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Train bal Acc</td><td>█▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">Classifier train</strong>: <a href=\"https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3gpn2vdk\" target=\"_blank\">https://wandb.ai/sleep_hacking/RP-fulltrain/runs/3gpn2vdk</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_WJ9mXMak4"
      },
      "source": [
        "# Train clf on concatenated train and val embed"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}